{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SanyaKapoor/netFound/blob/main/Part_III_NetFound_vs_DeepPacket.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Comparison with DeepPacket"
      ],
      "metadata": {
        "id": "A0_2hOPz5jnv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###DeepPacket expects Parquet files, however, we are working with pcaps, so we will convert them to desired format and then evaluate the pre-trained model."
      ],
      "metadata": {
        "id": "5ZPONmFs5mmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scapy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WusJzDrS85Th",
        "outputId": "ebd12024-c1bb-4d16-d756-ee4675f03a20"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scapy\n",
            "  Downloading scapy-2.6.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Downloading scapy-2.6.1-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scapy\n",
            "Successfully installed scapy-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning==1.8.5\n",
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPYU2wCVAvty",
        "outputId": "74ca73e7-b04a-4219-c520-aab583789705"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-lightning==1.8.5\n",
            "  Downloading pytorch_lightning-1.8.5-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.8.5) (2.0.2)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.8.5) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.8.5) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.8.5) (6.0.2)\n",
            "Requirement already satisfied: fsspec>2021.06.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning==1.8.5) (2025.3.2)\n",
            "Collecting tensorboardX>=2.2 (from pytorch-lightning==1.8.5)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning==1.8.5)\n",
            "  Downloading torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.8.5) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.8.5) (4.13.2)\n",
            "Collecting lightning-utilities!=0.4.0,>=0.3.0 (from pytorch-lightning==1.8.5)\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning==1.8.5) (3.11.15)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities!=0.4.0,>=0.3.0->pytorch-lightning==1.8.5) (75.2.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX>=2.2->pytorch-lightning==1.8.5) (5.29.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->pytorch-lightning==1.8.5) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->pytorch-lightning==1.8.5) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->pytorch-lightning==1.8.5) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.9.0->pytorch-lightning==1.8.5)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.9.0->pytorch-lightning==1.8.5)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.9.0->pytorch-lightning==1.8.5)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.9.0->pytorch-lightning==1.8.5)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.9.0->pytorch-lightning==1.8.5)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.9.0->pytorch-lightning==1.8.5)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.9.0->pytorch-lightning==1.8.5)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.9.0->pytorch-lightning==1.8.5)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.9.0->pytorch-lightning==1.8.5)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->pytorch-lightning==1.8.5) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->pytorch-lightning==1.8.5) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->pytorch-lightning==1.8.5) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.9.0->pytorch-lightning==1.8.5)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->pytorch-lightning==1.8.5) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->pytorch-lightning==1.8.5) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9.0->pytorch-lightning==1.8.5) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.5) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.5) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.5) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.5) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.5) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.5) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.5) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9.0->pytorch-lightning==1.8.5) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.8.5) (3.10)\n",
            "Downloading pytorch_lightning-1.8.5-py3-none-any.whl (800 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.4/800.4 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboardX, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, pytorch-lightning\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed lightning-utilities-0.14.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch-lightning-1.8.5 tensorboardX-2.6.2.2 torchmetrics-1.7.1\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_cnn(\n",
        "    c1_kernel_size,\n",
        "    c1_output_dim,\n",
        "    c1_stride,\n",
        "    c2_kernel_size,\n",
        "    c2_output_dim,\n",
        "    c2_stride,\n",
        "    output_dim,\n",
        "    data_path,\n",
        "    epoch,\n",
        "    model_path,\n",
        "    signal_length,\n",
        "    logger,\n",
        "):\n",
        "    # prepare dir for model path\n",
        "    if model_path:\n",
        "        model_path = Path(model_path)\n",
        "        model_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # seed everything\n",
        "    seed_everything(seed=9876, workers=True)\n",
        "\n",
        "    model = CNN(\n",
        "        c1_kernel_size=c1_kernel_size,\n",
        "        c1_output_dim=c1_output_dim,\n",
        "        c1_stride=c1_stride,\n",
        "        c2_kernel_size=c2_kernel_size,\n",
        "        c2_output_dim=c2_output_dim,\n",
        "        c2_stride=c2_stride,\n",
        "        output_dim=output_dim,\n",
        "        data_path=data_path,\n",
        "        signal_length=signal_length,\n",
        "    ).float()\n",
        "    trainer = Trainer(\n",
        "        val_check_interval=1.0,\n",
        "        max_epochs=epoch,\n",
        "        devices=\"auto\",\n",
        "        accelerator=\"auto\",\n",
        "        logger=logger,\n",
        "        callbacks=[\n",
        "            EarlyStopping(\n",
        "                monitor=\"training_loss\", mode=\"min\", check_on_train_epoch_end=True\n",
        "            )\n",
        "        ],\n",
        "    )\n",
        "    trainer.fit(model)\n",
        "\n",
        "    # save model\n",
        "    trainer.save_checkpoint(str(model_path.absolute()))\n",
        "\n",
        "\n",
        "def train_resnet(\n",
        "    c1_kernel_size,\n",
        "    c1_output_dim,\n",
        "    c1_stride,\n",
        "    c1_groups,\n",
        "    c1_n_block,\n",
        "    output_dim,\n",
        "    data_path,\n",
        "    epoch,\n",
        "    model_path,\n",
        "    signal_length,\n",
        "    logger,\n",
        "):\n",
        "    # prepare dir for model path\n",
        "    if model_path:\n",
        "        model_path = Path(model_path)\n",
        "        model_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # seed everything\n",
        "    seed_everything(seed=9876, workers=True)\n",
        "\n",
        "    model = ResNet(\n",
        "        c1_kernel_size=c1_kernel_size,\n",
        "        c1_output_dim=c1_output_dim,\n",
        "        c1_stride=c1_stride,\n",
        "        c1_groups=c1_groups,\n",
        "        c1_n_block=c1_n_block,\n",
        "        output_dim=output_dim,\n",
        "        data_path=data_path,\n",
        "        signal_length=signal_length,\n",
        "    ).float()\n",
        "    trainer = Trainer(\n",
        "        val_check_interval=1.0,\n",
        "        max_epochs=epoch,\n",
        "        devices=\"auto\",\n",
        "        accelerator=\"auto\",\n",
        "        logger=logger,\n",
        "        callbacks=[\n",
        "            EarlyStopping(\n",
        "                monitor=\"training_loss\", mode=\"min\", check_on_train_epoch_end=True\n",
        "            )\n",
        "        ],\n",
        "    )\n",
        "    trainer.fit(model)\n",
        "\n",
        "    # save model\n",
        "    trainer.save_checkpoint(str(model_path.absolute()))\n",
        "\n",
        "\n",
        "def train_application_classification_cnn_model(data_path, model_path):\n",
        "    logger = TensorBoardLogger(\n",
        "        \"application_classification_cnn_logs\", \"application_classification_cnn\"\n",
        "    )\n",
        "    train_cnn(\n",
        "        c1_kernel_size=4,\n",
        "        c1_output_dim=200,\n",
        "        c1_stride=3,\n",
        "        c2_kernel_size=5,\n",
        "        c2_output_dim=200,\n",
        "        c2_stride=1,\n",
        "        output_dim=17,\n",
        "        data_path=data_path,\n",
        "        epoch=20,\n",
        "        model_path=model_path,\n",
        "        signal_length=1500,\n",
        "        logger=logger,\n",
        "    )\n",
        "\n",
        "\n",
        "def train_application_classification_resnet_model(data_path, model_path):\n",
        "    logger = TensorBoardLogger(\n",
        "        \"application_classification_resnet_logs\", \"application_classification_resnet\"\n",
        "    )\n",
        "    train_resnet(\n",
        "        c1_kernel_size=4,\n",
        "        c1_output_dim=16,\n",
        "        c1_stride=3,\n",
        "        c1_groups=1,\n",
        "        c1_n_block=4,\n",
        "        output_dim=17,\n",
        "        data_path=data_path,\n",
        "        epoch=40,\n",
        "        model_path=model_path,\n",
        "        signal_length=1500,\n",
        "        logger=logger,\n",
        "    )\n",
        "\n",
        "\n",
        "def train_traffic_classification_cnn_model(data_path, model_path):\n",
        "    logger = TensorBoardLogger(\n",
        "        \"traffic_classification_cnn_logs\", \"traffic_classification_cnn\"\n",
        "    )\n",
        "    train_cnn(\n",
        "        c1_kernel_size=5,\n",
        "        c1_output_dim=200,\n",
        "        c1_stride=3,\n",
        "        c2_kernel_size=4,\n",
        "        c2_output_dim=200,\n",
        "        c2_stride=3,\n",
        "        output_dim=12,\n",
        "        data_path=data_path,\n",
        "        epoch=20,\n",
        "        model_path=model_path,\n",
        "        signal_length=1500,\n",
        "        logger=logger,\n",
        "    )\n",
        "\n",
        "\n",
        "def train_traffic_classification_resnet_model(data_path, model_path):\n",
        "    logger = TensorBoardLogger(\n",
        "        \"traffic_classification_resnet_logs\", \"traffic_classification_resnet\"\n",
        "    )\n",
        "    train_resnet(\n",
        "        c1_kernel_size=5,\n",
        "        c1_output_dim=16,\n",
        "        c1_stride=3,\n",
        "        c1_groups=1,\n",
        "        c1_n_block=4,\n",
        "        output_dim=12,\n",
        "        data_path=data_path,\n",
        "        epoch=40,\n",
        "        model_path=model_path,\n",
        "        signal_length=1500,\n",
        "        logger=logger,\n",
        "    )\n",
        "\n",
        "\n",
        "def load_cnn_model(model_path, gpu):\n",
        "    if gpu:\n",
        "        device = \"cuda\"\n",
        "    else:\n",
        "        device = \"cpu\"\n",
        "    model = (\n",
        "        CNN.load_from_checkpoint(\n",
        "            str(Path(model_path).absolute()), map_location=torch.device(device)\n",
        "        )\n",
        "        .float()\n",
        "        .to(device)\n",
        "    )\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def load_resnet_model(model_path, gpu):\n",
        "    if gpu:\n",
        "        device = \"cuda\"\n",
        "    else:\n",
        "        device = \"cpu\"\n",
        "    model = (\n",
        "        ResNet.load_from_checkpoint(\n",
        "            str(Path(model_path).absolute()), map_location=torch.device(device)\n",
        "        )\n",
        "        .float()\n",
        "        .to(device)\n",
        "    )\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def load_application_classification_cnn_model(model_path, gpu=False):\n",
        "    return load_cnn_model(model_path=model_path, gpu=gpu)\n",
        "\n",
        "\n",
        "def load_application_classification_resnet_model(model_path, gpu=False):\n",
        "    return load_resnet_model(model_path=model_path, gpu=gpu)\n",
        "\n",
        "\n",
        "def load_traffic_classification_cnn_model(model_path, gpu=False):\n",
        "    return load_cnn_model(model_path=model_path, gpu=gpu)\n",
        "\n",
        "\n",
        "def load_traffic_classification_resnet_model(model_path, gpu=False):\n",
        "    return load_resnet_model(model_path=model_path, gpu=gpu)\n",
        "\n",
        "\n",
        "def normalise_cm(cm):\n",
        "    with np.errstate(all=\"ignore\"):\n",
        "        normalised_cm = cm / cm.sum(axis=1, keepdims=True)\n",
        "        normalised_cm = np.nan_to_num(normalised_cm)\n",
        "        return normalised_cm\n",
        "\n",
        "def dataset_collate_function(batch):\n",
        "    feature = torch.stack([torch.tensor([data[\"feature\"]]) for data in batch])\n",
        "    label = torch.tensor([data[\"label\"] for data in batch])\n",
        "    transformed_batch = {\"feature\": feature, \"label\": label}\n",
        "    return transformed_batch\n",
        "\n",
        "import multiprocessing\n",
        "\n",
        "import datasets\n",
        "import torch\n",
        "from pytorch_lightning import LightningModule\n",
        "from torch import nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class CNN(LightningModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        c1_output_dim,\n",
        "        c1_kernel_size,\n",
        "        c1_stride,\n",
        "        c2_output_dim,\n",
        "        c2_kernel_size,\n",
        "        c2_stride,\n",
        "        output_dim,\n",
        "        data_path,\n",
        "        signal_length,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        # save parameters to checkpoint\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        # two convolution, then one max pool\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv1d(\n",
        "                in_channels=1,\n",
        "                out_channels=self.hparams.c1_output_dim,\n",
        "                kernel_size=self.hparams.c1_kernel_size,\n",
        "                stride=self.hparams.c1_stride,\n",
        "            ),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv1d(\n",
        "                in_channels=self.hparams.c1_output_dim,\n",
        "                out_channels=self.hparams.c2_output_dim,\n",
        "                kernel_size=self.hparams.c2_kernel_size,\n",
        "                stride=self.hparams.c2_stride,\n",
        "            ),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.max_pool = nn.MaxPool1d(kernel_size=2)\n",
        "\n",
        "        # flatten, calculate the output size of max pool\n",
        "        # use a dummy input to calculate\n",
        "        dummy_x = torch.rand(1, 1, self.hparams.signal_length, requires_grad=False)\n",
        "        dummy_x = self.conv1(dummy_x)\n",
        "        dummy_x = self.conv2(dummy_x)\n",
        "        dummy_x = self.max_pool(dummy_x)\n",
        "        max_pool_out = dummy_x.view(1, -1).shape[1]\n",
        "\n",
        "        # followed by 5 dense layers\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(in_features=max_pool_out, out_features=200),\n",
        "            nn.Dropout(p=0.05),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.fc2 = nn.Sequential(\n",
        "            nn.Linear(in_features=200, out_features=100), nn.Dropout(p=0.05), nn.ReLU()\n",
        "        )\n",
        "        self.fc3 = nn.Sequential(\n",
        "            nn.Linear(in_features=100, out_features=50), nn.Dropout(p=0.05), nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # finally, output layer\n",
        "        self.out = nn.Linear(in_features=50, out_features=self.hparams.output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # make sure the input is in [batch_size, channel, signal_length]\n",
        "        # where channel is 1\n",
        "        # signal_length is 1500 by default\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        # 2 conv 1 max\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.max_pool(x)\n",
        "\n",
        "        x = x.reshape(batch_size, -1)\n",
        "\n",
        "        # 3 fc\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        # output\n",
        "        x = self.out(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        # expect to get train folder\n",
        "        dataset_dict = datasets.load_dataset(self.hparams.data_path)\n",
        "        dataset = dataset_dict[list(dataset_dict.keys())[0]]\n",
        "        try:\n",
        "            num_workers = multiprocessing.cpu_count()\n",
        "        except:\n",
        "            num_workers = 1\n",
        "        dataloader = DataLoader(\n",
        "            dataset,\n",
        "            batch_size=16,\n",
        "            num_workers=num_workers,\n",
        "            collate_fn=dataset_collate_function,\n",
        "            shuffle=True,\n",
        "        )\n",
        "\n",
        "        return dataloader\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters())\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x = batch[\"feature\"].float()\n",
        "        y = batch[\"label\"].long()\n",
        "        y_hat = self(x)\n",
        "\n",
        "        entropy = F.cross_entropy(y_hat, y)\n",
        "        self.log(\n",
        "            \"training_loss\",\n",
        "            entropy,\n",
        "            prog_bar=True,\n",
        "            logger=True,\n",
        "            on_step=True,\n",
        "            on_epoch=True,\n",
        "        )\n",
        "        loss = {\"loss\": entropy}\n",
        "\n",
        "        return loss\n",
        "\n",
        "\n",
        "class CustomConv1d(nn.Module):\n",
        "    \"\"\"\n",
        "    extend nn.Conv1d to support SAME padding\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, groups=1):\n",
        "        super(CustomConv1d, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.groups = groups\n",
        "        self.conv = torch.nn.Conv1d(\n",
        "            in_channels=self.in_channels,\n",
        "            out_channels=self.out_channels,\n",
        "            kernel_size=self.kernel_size,\n",
        "            stride=self.stride,\n",
        "            groups=self.groups,\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        net = x\n",
        "\n",
        "        # compute pad shape\n",
        "        in_dim = net.shape[-1]\n",
        "        out_dim = (in_dim + self.stride - 1) // self.stride\n",
        "        p = max(0, (out_dim - 1) * self.stride + self.kernel_size - in_dim)\n",
        "        pad_left = p // 2\n",
        "        pad_right = p - pad_left\n",
        "        net = F.pad(net, (pad_left, pad_right), \"constant\", 0)\n",
        "\n",
        "        net = self.conv(net)\n",
        "\n",
        "        return net\n",
        "\n",
        "\n",
        "class CustomMaxPool1d(nn.Module):\n",
        "    \"\"\"\n",
        "    extend nn.MaxPool1d to support SAME padding\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, kernel_size):\n",
        "        super(CustomMaxPool1d, self).__init__()\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = 1\n",
        "        self.max_pool = torch.nn.MaxPool1d(kernel_size=self.kernel_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        net = x\n",
        "\n",
        "        # compute pad shape\n",
        "        in_dim = net.shape[-1]\n",
        "        out_dim = (in_dim + self.stride - 1) // self.stride\n",
        "        p = max(0, (out_dim - 1) * self.stride + self.kernel_size - in_dim)\n",
        "        pad_left = p // 2\n",
        "        pad_right = p - pad_left\n",
        "        net = F.pad(net, (pad_left, pad_right), \"constant\", 0)\n",
        "\n",
        "        net = self.max_pool(net)\n",
        "\n",
        "        return net\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    ResNet Basic Block\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels,\n",
        "        out_channels,\n",
        "        kernel_size,\n",
        "        stride,\n",
        "        groups,\n",
        "        downsample,\n",
        "        use_bn,\n",
        "        use_do,\n",
        "        is_first_block=False,\n",
        "    ):\n",
        "        super(BasicBlock, self).__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.out_channels = out_channels\n",
        "        self.stride = stride\n",
        "        self.groups = groups\n",
        "        self.downsample = downsample\n",
        "        if self.downsample:\n",
        "            self.stride = stride\n",
        "        else:\n",
        "            self.stride = 1\n",
        "        self.is_first_block = is_first_block\n",
        "        self.use_bn = use_bn\n",
        "        self.use_do = use_do\n",
        "\n",
        "        # the first conv\n",
        "        self.bn1 = nn.BatchNorm1d(in_channels)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.do1 = nn.Dropout(p=0.5)\n",
        "        self.conv1 = CustomConv1d(\n",
        "            in_channels=in_channels,\n",
        "            out_channels=out_channels,\n",
        "            kernel_size=kernel_size,\n",
        "            stride=self.stride,\n",
        "            groups=self.groups,\n",
        "        )\n",
        "\n",
        "        # the second conv\n",
        "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.do2 = nn.Dropout(p=0.5)\n",
        "        self.conv2 = CustomConv1d(\n",
        "            in_channels=out_channels,\n",
        "            out_channels=out_channels,\n",
        "            kernel_size=kernel_size,\n",
        "            stride=1,\n",
        "            groups=self.groups,\n",
        "        )\n",
        "\n",
        "        self.max_pool = CustomMaxPool1d(kernel_size=self.stride)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        identity = x\n",
        "\n",
        "        # the first conv\n",
        "        out = x\n",
        "        if not self.is_first_block:\n",
        "            if self.use_bn:\n",
        "                out = self.bn1(out)\n",
        "            out = self.relu1(out)\n",
        "            if self.use_do:\n",
        "                out = self.do1(out)\n",
        "        out = self.conv1(out)\n",
        "\n",
        "        # the second conv\n",
        "        if self.use_bn:\n",
        "            out = self.bn2(out)\n",
        "        out = self.relu2(out)\n",
        "        if self.use_do:\n",
        "            out = self.do2(out)\n",
        "        out = self.conv2(out)\n",
        "\n",
        "        # if downsample, also downsample identity\n",
        "        if self.downsample:\n",
        "            identity = self.max_pool(identity)\n",
        "\n",
        "        # if expand channel, also pad zeros to identity\n",
        "        if self.out_channels != self.in_channels:\n",
        "            identity = identity.transpose(-1, -2)\n",
        "            ch1 = (self.out_channels - self.in_channels) // 2\n",
        "            ch2 = self.out_channels - self.in_channels - ch1\n",
        "            identity = F.pad(identity, (ch1, ch2), \"constant\", 0)\n",
        "            identity = identity.transpose(-1, -2)\n",
        "\n",
        "        # shortcut\n",
        "        out += identity\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet1d(nn.Module):\n",
        "    \"\"\"\n",
        "\n",
        "    Input:\n",
        "        X: (n_samples, n_channel, n_length)\n",
        "        Y: (n_samples)\n",
        "\n",
        "    Output:\n",
        "        out: (n_samples)\n",
        "\n",
        "    Pararmetes:\n",
        "        in_channels: dim of input, the same as n_channel\n",
        "        base_filters: number of filters in the first several Conv layer, it will double at every 4 layers\n",
        "        kernel_size: width of kernel\n",
        "        stride: stride of kernel moving\n",
        "        groups: set larget to 1 as ResNeXt\n",
        "        n_block: number of blocks\n",
        "        n_classes: number of classes\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels,\n",
        "        base_filters,\n",
        "        kernel_size,\n",
        "        stride,\n",
        "        groups,\n",
        "        n_block,\n",
        "        n_classes,\n",
        "        downsample_gap=2,\n",
        "        increasefilter_gap=4,\n",
        "        use_bn=True,\n",
        "        use_do=True,\n",
        "        verbose=False,\n",
        "    ):\n",
        "        super(ResNet1d, self).__init__()\n",
        "\n",
        "        self.verbose = verbose\n",
        "        self.n_block = n_block\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.groups = groups\n",
        "        self.use_bn = use_bn\n",
        "        self.use_do = use_do\n",
        "\n",
        "        self.downsample_gap = downsample_gap  # 2 for base model\n",
        "        self.increasefilter_gap = increasefilter_gap  # 4 for base model\n",
        "\n",
        "        # first block\n",
        "        self.first_block_conv = CustomConv1d(\n",
        "            in_channels=in_channels,\n",
        "            out_channels=base_filters,\n",
        "            kernel_size=self.kernel_size,\n",
        "            stride=1,\n",
        "        )\n",
        "        self.first_block_bn = nn.BatchNorm1d(base_filters)\n",
        "        self.first_block_relu = nn.ReLU()\n",
        "        out_channels = base_filters\n",
        "\n",
        "        # residual blocks\n",
        "        self.basicblock_list = nn.ModuleList()\n",
        "        for i_block in range(self.n_block):\n",
        "            # is_first_block\n",
        "            if i_block == 0:\n",
        "                is_first_block = True\n",
        "            else:\n",
        "                is_first_block = False\n",
        "            # downsample at every self.downsample_gap blocks\n",
        "            if i_block % self.downsample_gap == 1:\n",
        "                downsample = True\n",
        "            else:\n",
        "                downsample = False\n",
        "            # in_channels and out_channels\n",
        "            if is_first_block:\n",
        "                in_channels = base_filters\n",
        "                out_channels = in_channels\n",
        "            else:\n",
        "                # increase filters at every self.increasefilter_gap blocks\n",
        "                in_channels = int(\n",
        "                    base_filters * 2 ** ((i_block - 1) // self.increasefilter_gap)\n",
        "                )\n",
        "                if (i_block % self.increasefilter_gap == 0) and (i_block != 0):\n",
        "                    out_channels = in_channels * 2\n",
        "                else:\n",
        "                    out_channels = in_channels\n",
        "\n",
        "            tmp_block = BasicBlock(\n",
        "                in_channels=in_channels,\n",
        "                out_channels=out_channels,\n",
        "                kernel_size=self.kernel_size,\n",
        "                stride=self.stride,\n",
        "                groups=self.groups,\n",
        "                downsample=downsample,\n",
        "                use_bn=self.use_bn,\n",
        "                use_do=self.use_do,\n",
        "                is_first_block=is_first_block,\n",
        "            )\n",
        "            self.basicblock_list.append(tmp_block)\n",
        "\n",
        "        # final prediction\n",
        "        self.final_bn = nn.BatchNorm1d(out_channels)\n",
        "        self.final_relu = nn.ReLU(inplace=True)\n",
        "        # self.do = nn.Dropout(p=0.5)\n",
        "        self.dense = nn.Linear(out_channels, n_classes)\n",
        "        # self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        out = x\n",
        "\n",
        "        # first conv\n",
        "        if self.verbose:\n",
        "            print(\"input shape\", out.shape)\n",
        "        out = self.first_block_conv(out)\n",
        "        if self.verbose:\n",
        "            print(\"after first conv\", out.shape)\n",
        "        if self.use_bn:\n",
        "            out = self.first_block_bn(out)\n",
        "        out = self.first_block_relu(out)\n",
        "\n",
        "        # residual blocks, every block has two conv\n",
        "        for i_block in range(self.n_block):\n",
        "            net = self.basicblock_list[i_block]\n",
        "            if self.verbose:\n",
        "                print(\n",
        "                    \"i_block: {0}, in_channels: {1}, out_channels: {2}, downsample: {3}\".format(\n",
        "                        i_block, net.in_channels, net.out_channels, net.downsample\n",
        "                    )\n",
        "                )\n",
        "            out = net(out)\n",
        "            if self.verbose:\n",
        "                print(out.shape)\n",
        "\n",
        "        # final prediction\n",
        "        if self.use_bn:\n",
        "            out = self.final_bn(out)\n",
        "        out = self.final_relu(out)\n",
        "        out = out.mean(-1)\n",
        "        if self.verbose:\n",
        "            print(\"final pooling\", out.shape)\n",
        "        # out = self.do(out)\n",
        "        out = self.dense(out)\n",
        "        if self.verbose:\n",
        "            print(\"dense\", out.shape)\n",
        "        # out = self.softmax(out)\n",
        "        if self.verbose:\n",
        "            print(\"softmax\", out.shape)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(LightningModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        c1_output_dim,\n",
        "        c1_kernel_size,\n",
        "        c1_stride,\n",
        "        c1_groups,\n",
        "        c1_n_block,\n",
        "        output_dim,\n",
        "        data_path,\n",
        "        signal_length,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        # save parameters to checkpoint\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        # two convolution, then one max pool\n",
        "        self.conv1 = nn.Sequential(\n",
        "            ResNet1d(\n",
        "                in_channels=1,\n",
        "                base_filters=self.hparams.c1_output_dim,\n",
        "                kernel_size=self.hparams.c1_kernel_size,\n",
        "                stride=self.hparams.c1_stride,\n",
        "                groups=self.hparams.c1_groups,\n",
        "                n_block=self.hparams.c1_n_block,\n",
        "                n_classes=self.hparams.c1_output_dim,\n",
        "            ),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.max_pool = nn.MaxPool1d(kernel_size=2)\n",
        "\n",
        "        # flatten, calculate the output size of max pool\n",
        "        # use a dummy input to calculate\n",
        "        dummy_x = torch.rand(1, 1, self.hparams.signal_length, requires_grad=False)\n",
        "        dummy_x = self.conv1(dummy_x)\n",
        "        dummy_x = self.max_pool(dummy_x)\n",
        "        max_pool_out = dummy_x.view(1, -1).shape[1]\n",
        "\n",
        "        # followed by 5 dense layers\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(in_features=max_pool_out, out_features=200),\n",
        "            nn.Dropout(p=0.05),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.fc2 = nn.Sequential(\n",
        "            nn.Linear(in_features=200, out_features=100), nn.Dropout(p=0.05), nn.ReLU()\n",
        "        )\n",
        "        self.fc3 = nn.Sequential(\n",
        "            nn.Linear(in_features=100, out_features=50), nn.Dropout(p=0.05), nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # finally, output layer\n",
        "        self.out = nn.Linear(in_features=50, out_features=self.hparams.output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # make sure the input is in [batch_size, channel, signal_length]\n",
        "        # where channel is 1\n",
        "        # signal_length is 1500 by default\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        # 1 conv 1 max\n",
        "        x = self.conv1(x)\n",
        "        x = self.max_pool(x)\n",
        "\n",
        "        x = x.reshape(batch_size, -1)\n",
        "\n",
        "        # 3 fc\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        # output\n",
        "        x = self.out(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        # expect to get train folder\n",
        "        dataset_dict = datasets.load_dataset(self.hparams.data_path)\n",
        "        dataset = dataset_dict[list(dataset_dict.keys())[0]]\n",
        "        try:\n",
        "            num_workers = multiprocessing.cpu_count()\n",
        "        except:\n",
        "            num_workers = 1\n",
        "        dataloader = DataLoader(\n",
        "            dataset,\n",
        "            batch_size=16,\n",
        "            num_workers=num_workers,\n",
        "            collate_fn=dataset_collate_function,\n",
        "            shuffle=True,\n",
        "        )\n",
        "\n",
        "        return dataloader\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters())\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x = batch[\"feature\"].float()\n",
        "        y = batch[\"label\"].long()\n",
        "        y_hat = self(x)\n",
        "\n",
        "        entropy = F.cross_entropy(y_hat, y)\n",
        "        self.log(\n",
        "            \"training_loss\",\n",
        "            entropy,\n",
        "            prog_bar=True,\n",
        "            logger=True,\n",
        "            on_step=True,\n",
        "            on_epoch=True,\n",
        "        )\n",
        "        loss = {\"loss\": entropy}\n",
        "\n",
        "        return loss\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from pytorch_lightning.utilities.seed import seed_everything\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "from scapy.layers.dns import DNS\n",
        "from scapy.layers.inet import TCP\n",
        "from scapy.packet import Padding\n",
        "from scapy.utils import PcapReader"
      ],
      "metadata": {
        "id": "c_Gfd7vSABGd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2V5sjeP2lu9F",
        "outputId": "70c15dac-243b-423c-e36d-7d7c2a994fa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting fastparquet\n",
            "  Downloading fastparquet-2024.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from fastparquet) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fastparquet) (2.0.2)\n",
            "Requirement already satisfied: cramjam>=2.3 in /usr/local/lib/python3.11/dist-packages (from fastparquet) (2.10.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from fastparquet) (2024.12.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from fastparquet) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->fastparquet) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->fastparquet) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->fastparquet) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.17.0)\n",
            "Downloading fastparquet-2024.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fastparquet\n",
            "Successfully installed fastparquet-2024.11.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import torch\n",
        "import pyarrow.parquet as pq\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import gzip\n",
        "import json\n",
        "from joblib import Parallel, delayed\n",
        "from scapy.compat import raw\n",
        "from scapy.layers.inet import IP, UDP\n",
        "from scapy.layers.l2 import Ether\n",
        "from scapy.packet import Padding\n",
        "from scipy import sparse\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "from scapy.layers.dns import DNS\n",
        "from scapy.layers.inet import TCP\n",
        "from scapy.packet import Padding\n",
        "from scapy.utils import PcapReader\n",
        "\n",
        "def read_pcap(path: Path):\n",
        "    packets = PcapReader(str(path))\n",
        "\n",
        "    return packets\n",
        "\n",
        "def should_omit_packet(packet):\n",
        "    # SYN, ACK or FIN flags set to 1 and no payload\n",
        "    if TCP in packet and (packet.flags & 0x13):\n",
        "        # not payload or contains only padding\n",
        "        layers = packet[TCP].payload.layers()\n",
        "        if not layers or (Padding in layers and len(layers) == 1):\n",
        "            return True\n",
        "\n",
        "    # DNS segment\n",
        "    if DNS in packet:\n",
        "        return True\n",
        "\n",
        "    return False\n",
        "\n",
        "# Install Trustee if not already installed\n",
        "# !pip install trustee\n",
        "\n",
        "# from trustee.explainers import IntegratedGradients, Saliency\n",
        "# import trustee.visualizers as vis\n",
        "\n",
        "# Functions from your second code snippet for PCAP processing\n",
        "def remove_ether_header(packet):\n",
        "    if Ether in packet:\n",
        "        return packet[Ether].payload\n",
        "    return packet\n",
        "\n",
        "def mask_ip(packet):\n",
        "    if IP in packet:\n",
        "        packet[IP].src = \"0.0.0.0\"\n",
        "        packet[IP].dst = \"0.0.0.0\"\n",
        "    return packet\n",
        "\n",
        "def pad_udp(packet):\n",
        "    if UDP in packet:\n",
        "        layer_after = packet[UDP].payload.copy()\n",
        "        pad = Padding()\n",
        "        pad.load = \"\\x00\" * 12\n",
        "        layer_before = packet.copy()\n",
        "        layer_before[UDP].remove_payload()\n",
        "        packet = layer_before / pad / layer_after\n",
        "        return packet\n",
        "    return packet\n",
        "\n",
        "def packet_to_sparse_array(packet, max_length=1500):\n",
        "    arr = np.frombuffer(raw(packet), dtype=np.uint8)[0:max_length] / 255\n",
        "    if len(arr) < max_length:\n",
        "        pad_width = max_length - len(arr)\n",
        "        arr = np.pad(arr, pad_width=(0, pad_width), constant_values=0)\n",
        "    arr = sparse.csr_matrix(arr)\n",
        "    return arr\n",
        "\n",
        "def transform_packet(packet):\n",
        "    if should_omit_packet(packet):\n",
        "        return None\n",
        "    packet = remove_ether_header(packet)\n",
        "    packet = pad_udp(packet)\n",
        "    packet = mask_ip(packet)\n",
        "    arr = packet_to_sparse_array(packet)\n",
        "    return arr\n",
        "\n",
        "!pip install fastparquet\n",
        "\n",
        "def process_pcap_to_parquet(pcap_path, output_dir, batch_size=10000):\n",
        "    \"\"\"Process a PCAP file directly to Parquet format in batches.\"\"\"\n",
        "    print(f\"Processing {pcap_path}\")\n",
        "    output_path = Path(output_dir) / f\"{Path(pcap_path).name}.parquet\"\n",
        "\n",
        "    if output_path.exists():\n",
        "        print(f\"{output_path} already exists, skipping\")\n",
        "        return str(output_path)\n",
        "\n",
        "    # Reverse mapping from app name to ID\n",
        "    APP_NAME_TO_ID = {v.lower(): k for k, v in ID_TO_APP.items()}\n",
        "    filename_prefix = Path(pcap_path).stem.lower()\n",
        "    app_label = APP_NAME_TO_ID.get(filename_prefix)\n",
        "\n",
        "    if app_label is None:\n",
        "        print(f\"Warning: Could not determine label for {filename_prefix}\")\n",
        "        return None\n",
        "\n",
        "    rows = []\n",
        "    batch_id = 0\n",
        "    for i, packet in enumerate(read_pcap(pcap_path)):\n",
        "        arr = transform_packet(packet)\n",
        "        if arr is not None:\n",
        "            row = {\n",
        "                \"app_label\": app_label,\n",
        "                \"feature\": arr.todense().tolist()[0]\n",
        "            }\n",
        "            rows.append(row)\n",
        "\n",
        "        # Write a batch to Parquet\n",
        "        if len(rows) >= batch_size:\n",
        "            df_batch = pd.DataFrame(rows)\n",
        "            file_exists = Path(output_path).exists()\n",
        "            df_batch.to_parquet(\n",
        "                output_path,\n",
        "                index=False,\n",
        "                engine='fastparquet',\n",
        "                compression='snappy',\n",
        "                append=file_exists\n",
        "            )\n",
        "            #df_batch.to_parquet(output_path, index=False, engine='fastparquet', compression='snappy', append=True)\n",
        "            print(f\"Wrote batch {batch_id} with {len(rows)} rows\")\n",
        "            rows = []  # Clear memory\n",
        "            batch_id += 1\n",
        "\n",
        "    # Write remaining rows\n",
        "    if rows:\n",
        "        df_batch = pd.DataFrame(rows)\n",
        "        file_exists = Path(output_path).exists()\n",
        "\n",
        "        df_batch.to_parquet(output_path, index=False, engine='fastparquet', compression='snappy', append=True)\n",
        "        print(f\"Wrote final batch with {len(rows)} rows\")\n",
        "\n",
        "    print(f\"Finished processing {pcap_path}\")\n",
        "    return str(output_path)\n",
        "\n",
        "\n",
        "# Function to process multiple PCAP files in parallel\n",
        "def process_pcap_files(pcap_paths, output_dir, n_jobs=-1):\n",
        "    \"\"\"Process multiple PCAP files to parquet format\"\"\"\n",
        "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    parquet_paths = []\n",
        "    for pcap_path in pcap_paths:\n",
        "        parquet_path = process_pcap_to_parquet(pcap_path, output_dir)\n",
        "        parquet_paths.append(parquet_path)\n",
        "\n",
        "    return parquet_paths\n",
        "\n",
        "# Load your model\n",
        "def load_model(model_path):\n",
        "    \"\"\"Load the pretrained deep packet model\"\"\"\n",
        "    model = load_application_classification_cnn_model(model_path, gpu=True)\n",
        "    return model\n",
        "\n",
        "# Create PyTorch model wrapper for Trustee\n",
        "class TorchModelWrapper:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.model.eval()\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Handle reshaping if needed for CNN\n",
        "        if len(X.shape) == 2:\n",
        "            X = X[:, np.newaxis, :]  # Ensures shape (batch, channels=1, sequence_length)\n",
        "\n",
        "        # Convert to PyTorch tensor\n",
        "        X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "\n",
        "        # Get predictions\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(X_tensor)\n",
        "            probas = torch.softmax(outputs, dim=1).numpy()\n",
        "\n",
        "        return probas\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        return self.predict(X)\n",
        "\n",
        "# Load parquet data\n",
        "def load_parquet_data(parquet_path, max_samples=1000):\n",
        "    \"\"\"Load data from a parquet file\"\"\"\n",
        "    df = pd.read_parquet(parquet_path)\n",
        "\n",
        "    # Extract features and labels\n",
        "    X = np.array(df['feature'].tolist(), dtype=np.float32)\n",
        "    y = np.array(df['app_label'].tolist())\n",
        "\n",
        "    # Limit samples if needed\n",
        "    if max_samples and len(X) > max_samples:\n",
        "        indices = np.random.choice(len(X), max_samples, replace=False)\n",
        "        X = X[indices]\n",
        "        y = y[indices]\n",
        "\n",
        "    return X, y\n",
        "\n",
        "# # Analyze feature importance with Trustee\n",
        "# def analyze_feature_importance(model, X, y, class_names, output_dir):\n",
        "#     \"\"\"Analyze feature importance using Trustee\"\"\"\n",
        "#     # Create output directory\n",
        "#     Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "#     # Create model wrapper\n",
        "#     wrapped_model = TorchModelWrapper(model)\n",
        "\n",
        "#     # Define feature names\n",
        "#     feature_names = [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
        "\n",
        "#     # Create explainers\n",
        "#     ig_explainer = IntegratedGradients(wrapped_model,\n",
        "#                                       feature_names=feature_names,\n",
        "#                                       class_names=class_names)\n",
        "\n",
        "#     saliency_explainer = Saliency(wrapped_model,\n",
        "#                                  feature_names=feature_names,\n",
        "#                                  class_names=class_names)\n",
        "\n",
        "#     # Calculate importances\n",
        "#     results = {}\n",
        "\n",
        "#     # Use a smaller subset for explanation\n",
        "#     explanation_samples = min(20, len(X))\n",
        "#     X_explain = X[:explanation_samples]\n",
        "\n",
        "#     # For each class\n",
        "#     for class_id, app_name in class_names.items():\n",
        "#         print(f\"Analyzing class: {app_name} (ID: {class_id})\")\n",
        "\n",
        "#         # Calculate importances using different methods\n",
        "#         ig_importances = ig_explainer.explain(X_explain, y=np.ones(explanation_samples) * class_id)\n",
        "#         saliency_importances = saliency_explainer.explain(X_explain, y=np.ones(explanation_samples) * class_id)\n",
        "\n",
        "#         # Store results\n",
        "#         results[app_name] = {\n",
        "#             'integrated_gradients': ig_importances,\n",
        "#             'saliency': saliency_importances\n",
        "#         }\n",
        "\n",
        "#     # Visualize the results\n",
        "#     for app_name, methods in results.items():\n",
        "#         print(f\"Visualizing results for {app_name}...\")\n",
        "\n",
        "#         # Create a figure for this class\n",
        "#         plt.figure(figsize=(15, 12))\n",
        "\n",
        "#         # Plot Integrated Gradients results\n",
        "#         plt.subplot(2, 1, 1)\n",
        "#         ig_imp = methods['integrated_gradients'].mean(axis=0)\n",
        "#         top_n = 20\n",
        "#         sorted_idx = np.argsort(ig_imp)[-top_n:]\n",
        "#         plt.barh(range(len(sorted_idx)), ig_imp[sorted_idx])\n",
        "#         plt.yticks(range(len(sorted_idx)), [feature_names[i] for i in sorted_idx])\n",
        "#         plt.title(f\"Top {top_n} features for {app_name} (Integrated Gradients)\")\n",
        "#         plt.xlabel(\"Importance Score\")\n",
        "\n",
        "#         # Plot Saliency results\n",
        "#         plt.subplot(2, 1, 2)\n",
        "#         saliency_imp = methods['saliency'].mean(axis=0)\n",
        "#         sorted_idx = np.argsort(saliency_imp)[-top_n:]\n",
        "#         plt.barh(range(len(sorted_idx)), saliency_imp[sorted_idx])\n",
        "#         plt.yticks(range(len(sorted_idx)), [feature_names[i] for i in sorted_idx])\n",
        "#         plt.title(f\"Top {top_n} features for {app_name} (Saliency Maps)\")\n",
        "#         plt.xlabel(\"Importance Score\")\n",
        "\n",
        "#         plt.tight_layout()\n",
        "#         plt.savefig(f'{output_dir}/{app_name}_feature_importance.png', dpi=300)\n",
        "#         plt.close()\n",
        "\n",
        "#     # Calculate and visualize global importance\n",
        "#     global_importance = np.zeros((len(feature_names),))\n",
        "#     method_counts = 0\n",
        "\n",
        "#     for app_name, methods in results.items():\n",
        "#         for method_name, imp in methods.items():\n",
        "#             if len(imp.shape) > 1:\n",
        "#                 imp_avg = imp.mean(axis=0)\n",
        "#             else:\n",
        "#                 imp_avg = imp\n",
        "#             global_importance += imp_avg\n",
        "#             method_counts += 1\n",
        "\n",
        "#     global_importance /= method_counts\n",
        "\n",
        "#     plt.figure(figsize=(12, 8))\n",
        "#     top_n = 30\n",
        "#     sorted_idx = np.argsort(global_importance)[-top_n:]\n",
        "#     plt.barh(range(len(sorted_idx)), global_importance[sorted_idx])\n",
        "#     plt.yticks(range(len(sorted_idx)), [feature_names[i] for i in sorted_idx])\n",
        "#     plt.title(f\"Top {top_n} Global Feature Importance (Across All Classes and Methods)\")\n",
        "#     plt.xlabel(\"Importance Score\")\n",
        "#     plt.tight_layout()\n",
        "#     plt.savefig(f'{output_dir}/global_feature_importance.png', dpi=300)\n",
        "#     plt.show()\n",
        "\n",
        "#     # Save feature importance to CSV\n",
        "#     importance_df = pd.DataFrame(index=feature_names)\n",
        "\n",
        "#     # Save individual method results\n",
        "#     for app_name, methods in results.items():\n",
        "#         for method_name, imp in methods.items():\n",
        "#             if len(imp.shape) > 1:\n",
        "#                 imp_avg = imp.mean(axis=0)\n",
        "#             else:\n",
        "#                 imp_avg = imp\n",
        "#             importance_df[f\"{app_name}_{method_name}\"] = imp_avg\n",
        "\n",
        "#     # Add global importance\n",
        "#     importance_df['global'] = global_importance\n",
        "\n",
        "#     # Save to CSV\n",
        "#     importance_df.to_csv(f'{output_dir}/feature_importances.csv')\n",
        "#     print(f\"Feature importances saved to '{output_dir}/feature_importances.csv'\")\n",
        "\n",
        "#     return importance_df\n",
        "\n",
        "ID_TO_APP = {\n",
        "    0: \"AIM Chat\",\n",
        "    1: \"Email\",\n",
        "    2: \"Facebook\",\n",
        "    3: \"FTPS\",\n",
        "    4: \"Gmail\",\n",
        "    5: \"Hangouts\",\n",
        "    6: \"ICQ\",\n",
        "    7: \"Netflix\",\n",
        "    8: \"SCP\",\n",
        "    9: \"SFTP\",\n",
        "    10: \"Skype\",\n",
        "    11: \"Spotify\",\n",
        "    12: \"Vimeo\",\n",
        "    13: \"Voipbuster\",\n",
        "    14: \"Youtube\",\n",
        "}\n",
        "\n",
        "# for app identification\n",
        "PREFIX_TO_APP_ID = {\n",
        "    # AIM chat\n",
        "    \"aim_chat_3a\": 0,\n",
        "    \"aim_chat_3b\": 0,\n",
        "    \"aimchat1\": 0,\n",
        "    \"aimchat2\": 0,\n",
        "    # Email\n",
        "    \"email1a\": 1,\n",
        "    \"email1b\": 1,\n",
        "    \"email2a\": 1,\n",
        "    \"email2b\": 1,\n",
        "    # Facebook\n",
        "    \"facebook_audio1a\": 2,\n",
        "    \"facebook_audio1b\": 2,\n",
        "    \"facebook_audio2a\": 2,\n",
        "    \"facebook_audio2b\": 2,\n",
        "    \"facebook_audio3\": 2,\n",
        "    \"facebook_audio4\": 2,\n",
        "    \"facebook_chat_4a\": 2,\n",
        "    \"facebook_chat_4b\": 2,\n",
        "    \"facebook_video1a\": 2,\n",
        "    \"facebook_video1b\": 2,\n",
        "    \"facebook_video2a\": 2,\n",
        "    \"facebook_video2b\": 2,\n",
        "    \"facebookchat1\": 2,\n",
        "    \"facebookchat2\": 2,\n",
        "    \"facebookchat3\": 2,\n",
        "    # FTPS\n",
        "    \"ftps_down_1a\": 3,\n",
        "    \"ftps_down_1b\": 3,\n",
        "    \"ftps_up_2a\": 3,\n",
        "    \"ftps_up_2b\": 3,\n",
        "    # Gmail\n",
        "    \"gmailchat1\": 4,\n",
        "    \"gmailchat2\": 4,\n",
        "    \"gmailchat3\": 4,\n",
        "    # Hangouts\n",
        "    \"hangout_chat_4b\": 5,\n",
        "    \"hangouts_audio1a\": 5,\n",
        "    \"hangouts_audio1b\": 5,\n",
        "    \"hangouts_audio2a\": 5,\n",
        "    \"hangouts_audio2b\": 5,\n",
        "    \"hangouts_audio3\": 5,\n",
        "    \"hangouts_audio4\": 5,\n",
        "    \"hangouts_chat_4a\": 5,\n",
        "    \"hangouts_video1b\": 5,\n",
        "    \"hangouts_video2a\": 5,\n",
        "    \"hangouts_video2b\": 5,\n",
        "    # ICQ\n",
        "    \"icq_chat_3a\": 6,\n",
        "    \"icq_chat_3b\": 6,\n",
        "    \"icqchat1\": 6,\n",
        "    \"icqchat2\": 6,\n",
        "    # Netflix\n",
        "    \"netflix1\": 7,\n",
        "    \"netflix2\": 7,\n",
        "    \"netflix3\": 7,\n",
        "    \"netflix4\": 7,\n",
        "    # SCP\n",
        "    \"scp1\": 8,\n",
        "    \"scpdown1\": 8,\n",
        "    \"scpdown2\": 8,\n",
        "    \"scpdown3\": 8,\n",
        "    \"scpdown4\": 8,\n",
        "    \"scpdown5\": 8,\n",
        "    \"scpdown6\": 8,\n",
        "    \"scpup1\": 8,\n",
        "    \"scpup2\": 8,\n",
        "    \"scpup3\": 8,\n",
        "    \"scpup5\": 8,\n",
        "    \"scpup6\": 8,\n",
        "    # SFTP\n",
        "    \"sftp1\": 9,\n",
        "    \"sftp_down_3a\": 9,\n",
        "    \"sftp_down_3b\": 9,\n",
        "    \"sftp_up_2a\": 9,\n",
        "    \"sftp_up_2b\": 9,\n",
        "    \"sftpdown1\": 9,\n",
        "    \"sftpdown2\": 9,\n",
        "    \"sftpup1\": 9,\n",
        "    # Skype\n",
        "    \"skype_audio1a\": 10,\n",
        "    \"skype_audio1b\": 10,\n",
        "    \"skype_audio2a\": 10,\n",
        "    \"skype_audio2b\": 10,\n",
        "    \"skype_audio3\": 10,\n",
        "    \"skype_audio4\": 10,\n",
        "    \"skype_chat1a\": 10,\n",
        "    \"skype_chat1b\": 10,\n",
        "    \"skype_file1\": 10,\n",
        "    \"skype_file2\": 10,\n",
        "    \"skype_file3\": 10,\n",
        "    \"skype_file4\": 10,\n",
        "    \"skype_file5\": 10,\n",
        "    \"skype_file6\": 10,\n",
        "    \"skype_file7\": 10,\n",
        "    \"skype_file8\": 10,\n",
        "    \"skype_video1a\": 10,\n",
        "    \"skype_video1b\": 10,\n",
        "    \"skype_video2a\": 10,\n",
        "    \"skype_video2b\": 10,\n",
        "    # Spotify\n",
        "    \"spotify1\": 11,\n",
        "    \"spotify2\": 11,\n",
        "    \"spotify3\": 11,\n",
        "    \"spotify4\": 11,\n",
        "    # Vimeo\n",
        "    \"vimeo1\": 12,\n",
        "    \"vimeo2\": 12,\n",
        "    \"vimeo3\": 12,\n",
        "    \"vimeo4\": 12,\n",
        "    # Voipbuster\n",
        "    \"voipbuster1b\": 13,\n",
        "    \"voipbuster2b\": 13,\n",
        "    \"voipbuster3b\": 13,\n",
        "    \"voipbuster_4a\": 13,\n",
        "    \"voipbuster_4b\": 13,\n",
        "    # Youtube\n",
        "    \"youtube1\": 14,\n",
        "    \"youtube2\": 14,\n",
        "    \"youtube3\": 14,\n",
        "    \"youtube4\": 14,\n",
        "    \"youtube5\": 14,\n",
        "    \"youtube6\": 14,\n",
        "    \"youtubehtml5_1\": 14,\n",
        "}\n",
        "\n",
        "def load_cnn_model(model_path, gpu):\n",
        "    if gpu:\n",
        "        device = \"cuda\"\n",
        "    else:\n",
        "        device = \"cpu\"\n",
        "    model = (\n",
        "        CNN.load_from_checkpoint(\n",
        "            str(Path(model_path).absolute()), map_location=torch.device(device)\n",
        "        )\n",
        "        .float()\n",
        "        .to(device)\n",
        "    )\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    return model\n",
        "\n",
        "# Main function to orchestrate everything\n",
        "def main(pcap_paths, model_path, output_dir, n_jobs=-1):\n",
        "    \"\"\"Main function to process PCAP files and analyze feature importance\"\"\"\n",
        "    # Step 1: Process PCAP files to parquet\n",
        "    parquet_dir = os.path.join(output_dir, \"parquet_files\")\n",
        "    parquet_paths = process_pcap_files(pcap_paths, parquet_dir, n_jobs)\n",
        "\n",
        "    # Step 2: Load model\n",
        "    model = load_model(model_path)\n",
        "\n",
        "    # Step 3: Define class names\n",
        "    class_names = ID_TO_APP  # Assuming this is available from your code\n",
        "\n",
        "    # Step 4: Analyze each parquet file\n",
        "    for parquet_path in parquet_paths:\n",
        "        print(f\"Analyzing {parquet_path}\")\n",
        "\n",
        "        # Create output directory for this file\n",
        "        file_name = Path(parquet_path).stem\n",
        "        file_output_dir = os.path.join(output_dir, \"analysis\", file_name)\n",
        "\n",
        "        # Load data\n",
        "        X, y = load_parquet_data(parquet_path)\n",
        "\n",
        "        # # Analyze feature importance\n",
        "        # analyze_feature_importance(model, X, y, class_names, file_output_dir)\n",
        "\n",
        "    print(\"Analysis complete!\")\n",
        "\n",
        "def load_application_classification_cnn_model(model_path, gpu=False):\n",
        "    return load_cnn_model(model_path=model_path, gpu=gpu)\n",
        "\n",
        "# # Example usage\n",
        "# if __name__ == \"__main__\":\n",
        "#     # Define paths to your 6 large PCAP files\n",
        "#     pcap_paths = [\n",
        "#         \"/content/drive/My Drive/NetFound/Shiva_Folder/netFound/data/test/test_finetuning/raw/0/Netflix.pcap\",\n",
        "#         \"/content/drive/My Drive/NetFound/Shiva_Folder/netFound/data/test/test_finetuning/raw/1/Youtube.pcap\",\n",
        "#         \"/content/drive/My Drive/NetFound/Shiva_Folder/netFound/data/test/test_finetuning/raw/2/Gmail.pcap\",\n",
        "#         \"/content/drive/My Drive/NetFound/Shiva_Folder/netFound/data/test/test_finetuning/raw/3/Skype.pcap\",\n",
        "#         \"/content/drive/My Drive/NetFound/Shiva_Folder/netFound/data/test/test_finetuning/raw/4/Linkedin.pcap\",\n",
        "#         \"/content/drive/My Drive/NetFound/Shiva_Folder/netFound/data/test/test_finetuning/raw/5/Twitter.pcap\"\n",
        "#     ]\n",
        "\n",
        "#     # Path to your pretrained model\n",
        "#     model_path = \"/content/drive/My Drive/COL867_Assignment2/application_classification.cnn.model\"\n",
        "\n",
        "#     # Output directory\n",
        "#     output_dir = \"/content/drive/My Drive/NetFound/Parquet_Part3\"\n",
        "\n",
        "#     # Run the analysis\n",
        "#     main(pcap_paths, model_path, output_dir, n_jobs=-1)  # Adjust n_jobs based on your CPU"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Evaluation"
      ],
      "metadata": {
        "id": "w9YfUvl0C2ya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "# Monkey patch to fix deprecated usage\n",
        "np.float = float\n",
        "\n",
        "def load_parquet_data(parquet_path, max_samples=None):\n",
        "    \"\"\"Load data from a parquet file\"\"\"\n",
        "    df = pd.read_parquet(parquet_path)\n",
        "\n",
        "    # Extract features and labels\n",
        "    X = np.array(df['feature'].tolist(), dtype=np.float32)\n",
        "    y = np.array(df['app_label'].tolist()) if 'app_label' in df.columns else np.array(df['label'].tolist())\n",
        "\n",
        "    # Limit samples if needed\n",
        "    if max_samples and len(X) > max_samples:\n",
        "        indices = np.random.choice(len(X), max_samples, replace=False)\n",
        "        X = X[indices]\n",
        "        y = y[indices]\n",
        "\n",
        "    if 'app_label' in df.columns:\n",
        "        y = np.array(df['app_label'].tolist())\n",
        "        print(\"Using 'app_label' as target.\")\n",
        "    else:\n",
        "        y = np.array(df['label'].tolist())\n",
        "        print(\"Using 'label' as target.\")\n",
        "\n",
        "    # Print some information to verify\n",
        "    print(f\"Sample labels (first 10): {y[:10]}\")\n",
        "    print(f\"Unique labels in this parquet: {np.unique(y)}\")\n",
        "    print(f\"Label distribution:\\n{pd.Series(y).value_counts()}\")\n",
        "\n",
        "    return X, y\n",
        "\n",
        "def evaluate_model(model, parquet_path, batch_size=32):\n",
        "    \"\"\"Evaluate model performance on a parquet file\"\"\"\n",
        "    # Load data\n",
        "    X, y_true = load_parquet_data(parquet_path)\n",
        "\n",
        "    # Prepare data for model\n",
        "    if len(X.shape) == 2:\n",
        "        X = X[:, np.newaxis, :]  # Reshape for CNN if needed (batch, channels=1, sequence_length)\n",
        "\n",
        "    # Make predictions in batches to avoid memory issues\n",
        "    model.eval()\n",
        "    y_pred = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(X), batch_size):\n",
        "            batch_X = torch.tensor(X[i:i+batch_size], dtype=torch.float32)\n",
        "            outputs = model(batch_X)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "    f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # # Detailed classification report\n",
        "    # report = classification_report(y_true, y_pred, target_names=[ID_TO_APP[i] for i in sorted(set(y_true))])\n",
        "\n",
        "    labels = sorted(set(y_true))  # or list of expected label indices\n",
        "    target_names = [ID_TO_APP[i] for i in labels]\n",
        "\n",
        "    report = classification_report(y_true, y_pred, labels=labels, target_names=target_names)\n",
        "\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'f1_macro': f1_macro,\n",
        "        'f1_weighted': f1_weighted,\n",
        "        'confusion_matrix': cm,\n",
        "        'classification_report': report\n",
        "    }\n",
        "\n",
        "def evaluate_all_parquets(model_path, parquet_paths, output_dir):\n",
        "    \"\"\"Evaluate model on multiple parquet files and save results\"\"\"\n",
        "    # Create output directory\n",
        "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Load model\n",
        "    model = load_application_classification_cnn_model(model_path, gpu=False)\n",
        "\n",
        "    # Overall results dictionary\n",
        "    all_results = {}\n",
        "\n",
        "    # Evaluate each parquet file\n",
        "    for parquet_path in parquet_paths:\n",
        "        file_name = Path(parquet_path).stem\n",
        "        print(f\"Evaluating model on {file_name}...\")\n",
        "\n",
        "        results = evaluate_model(model, parquet_path)\n",
        "        all_results[file_name] = results\n",
        "\n",
        "        # Print results\n",
        "        print(f\"Results for {file_name}:\")\n",
        "        print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
        "        print(f\"F1 Score (Macro): {results['f1_macro']:.4f}\")\n",
        "        print(f\"F1 Score (Weighted): {results['f1_weighted']:.4f}\")\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(results['classification_report'])\n",
        "        print(\"\\nConfusion Matrix:\")\n",
        "        print(results['confusion_matrix'])\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        # Save confusion matrix visualization\n",
        "        plt.figure(figsize=(12, 10))\n",
        "        cm = results['confusion_matrix']\n",
        "        class_names = [ID_TO_APP[i] for i in range(len(ID_TO_APP)) if i in set(np.unique(np.concatenate([cm.reshape(-1), np.arange(len(ID_TO_APP))])))]\n",
        "\n",
        "\n",
        "\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('True')\n",
        "        plt.title(f'Confusion Matrix - {file_name}')\n",
        "        plt.savefig(f'{output_dir}/{file_name}_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    # Aggregate results across all files\n",
        "    print(\"Aggregating results across all files...\")\n",
        "\n",
        "    # Calculate average metrics\n",
        "    avg_accuracy = np.mean([results['accuracy'] for results in all_results.values()])\n",
        "    avg_f1_macro = np.mean([results['f1_macro'] for results in all_results.values()])\n",
        "    avg_f1_weighted = np.mean([results['f1_weighted'] for results in all_results.values()])\n",
        "\n",
        "    # Save summary to CSV\n",
        "    summary_df = pd.DataFrame({\n",
        "        'file': list(all_results.keys()),\n",
        "        'accuracy': [results['accuracy'] for results in all_results.values()],\n",
        "        'f1_macro': [results['f1_macro'] for results in all_results.values()],\n",
        "        'f1_weighted': [results['f1_weighted'] for results in all_results.values()]\n",
        "    })\n",
        "\n",
        "    # Add average row\n",
        "    summary_df.loc[len(summary_df)] = ['AVERAGE', avg_accuracy, avg_f1_macro, avg_f1_weighted]\n",
        "\n",
        "    # Save to CSV\n",
        "    summary_df.to_csv(f'{output_dir}/evaluation_summary.csv', index=False)\n",
        "\n",
        "    print(\"Evaluation complete!\")\n",
        "    print(f\"Average Accuracy: {avg_accuracy:.4f}\")\n",
        "    print(f\"Average F1 Score (Macro): {avg_f1_macro:.4f}\")\n",
        "    print(f\"Average F1 Score (Weighted): {avg_f1_weighted:.4f}\")\n",
        "    print(f\"Detailed results saved to {output_dir}\")\n",
        "\n",
        "    return all_results\n",
        "\n",
        "# Run the evaluation\n",
        "if __name__ == \"__main__\":\n",
        "    # Import missing dependencies\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "\n",
        "    # Path to model\n",
        "    model_path = \"/content/drive/My Drive/COL867_Assignment2/application_classification.cnn.model\"\n",
        "\n",
        "    # List of parquet files to evaluate\n",
        "    parquet_paths = [\n",
        "        \"/content/drive/My Drive/NetFound/Parquet_Part3/parquet_files/Netflix.pcap.parquet\",\n",
        "        # \"/content/drive/My Drive/NetFound/Parquet_Part3/parquet_files/Youtube.pcap.parquet\",\n",
        "        # \"/content/drive/My Drive/NetFound/Parquet_Part3/parquet_files/Gmail.pcap.parquet\",\n",
        "        # \"/content/drive/My Drive/NetFound/Parquet_Part3/parquet_files/Skype.pcap.parquet\",\n",
        "        # \"/content/drive/My Drive/NetFound/Parquet_Part3/parquet_files/Linkedin.pcap.parquet\",\n",
        "        # \"/content/drive/My Drive/NetFound/Parquet_Part3/parquet_files/Twitter.pcap.parquet\"\n",
        "    ]\n",
        "\n",
        "    # Output directory\n",
        "    output_dir = \"/content/drive/My Drive/NetFound/\"\n",
        "\n",
        "    # Run evaluation\n",
        "    evaluate_all_parquets(model_path, parquet_paths, output_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1TT0W0fC60g",
        "outputId": "e039c0b4-5b74-4c09-f43c-dd39f5a43b9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating model on Netflix.pcap...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "np.float = float  # Monkey patch for older parquet files using np.float\n",
        "\n",
        "def load_parquet_data(parquet_path, max_samples=None):\n",
        "    \"\"\"Load features and labels from a parquet file.\"\"\"\n",
        "    df = pd.read_parquet(parquet_path)\n",
        "\n",
        "    if 'app_label' in df.columns:\n",
        "        y = df['app_label'].to_numpy()\n",
        "        print(\"Using 'app_label' as target.\")\n",
        "    else:\n",
        "        y = df['label'].to_numpy()\n",
        "        print(\"Using 'label' as target.\")\n",
        "\n",
        "    X = np.stack(df['feature'].values).astype(np.float32)\n",
        "\n",
        "    if max_samples and len(X) > max_samples:\n",
        "        idx = np.random.choice(len(X), max_samples, replace=False)\n",
        "        X, y = X[idx], y[idx]\n",
        "\n",
        "    print(f\"Sample labels (first 10): {y[:10]}\")\n",
        "    print(f\"Unique labels: {np.unique(y)}\")\n",
        "    print(f\"Label distribution:\\n{pd.Series(y).value_counts()}\")\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def predict_in_batches(model, X, batch_size=32):\n",
        "    \"\"\"Run model predictions in batches to save memory.\"\"\"\n",
        "    model.eval()\n",
        "    y_pred = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(X), batch_size):\n",
        "            batch = torch.tensor(X[i:i + batch_size], dtype=torch.float32)\n",
        "            outputs = model(batch)\n",
        "            preds = outputs.argmax(dim=1).cpu().numpy()\n",
        "            y_pred.extend(preds)\n",
        "\n",
        "    return np.array(y_pred)\n",
        "\n",
        "\n",
        "def evaluate_model(model, parquet_path, batch_size=32, label_map=None):\n",
        "    \"\"\"Evaluate a model on a single parquet file.\"\"\"\n",
        "    X, y_true = load_parquet_data(parquet_path)\n",
        "\n",
        "    if X.ndim == 2:\n",
        "        X = X[:, np.newaxis, :]\n",
        "\n",
        "    y_pred = predict_in_batches(model, X, batch_size)\n",
        "\n",
        "    results = {\n",
        "        'accuracy': accuracy_score(y_true, y_pred),\n",
        "        'f1_macro': f1_score(y_true, y_pred, average='macro'),\n",
        "        'f1_weighted': f1_score(y_true, y_pred, average='weighted'),\n",
        "        'confusion_matrix': confusion_matrix(y_true, y_pred),\n",
        "        'classification_report': classification_report(\n",
        "            y_true,\n",
        "            y_pred,\n",
        "            labels=sorted(set(y_true)),\n",
        "            target_names=[label_map[i] for i in sorted(set(y_true))] if label_map else None\n",
        "        )\n",
        "    }\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm, labels, title, save_path):\n",
        "    \"\"\"Plot and save confusion matrix.\"\"\"\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=labels, yticklabels=labels)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def evaluate_all_parquets(model_path, parquet_paths, output_dir, label_map):\n",
        "    \"\"\"Evaluate model on all parquet files and save results.\"\"\"\n",
        "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    model = load_application_classification_cnn_model(model_path, gpu=False)\n",
        "\n",
        "    all_results = {}\n",
        "\n",
        "    for parquet_path in parquet_paths:\n",
        "        file_name = Path(parquet_path).stem\n",
        "        print(f\"Evaluating {file_name}...\")\n",
        "\n",
        "        results = evaluate_model(model, parquet_path, label_map=label_map)\n",
        "        all_results[file_name] = results\n",
        "\n",
        "        print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
        "        print(f\"F1 Macro: {results['f1_macro']:.4f}\")\n",
        "        print(f\"F1 Weighted: {results['f1_weighted']:.4f}\")\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(results['classification_report'])\n",
        "\n",
        "        cm_path = os.path.join(output_dir, f\"{file_name}_confusion_matrix.png\")\n",
        "        plot_confusion_matrix(results['confusion_matrix'],\n",
        "                              [label_map[i] for i in sorted(set(np.unique(results['confusion_matrix'])))],\n",
        "                              f\"Confusion Matrix - {file_name}\",\n",
        "                              cm_path)\n",
        "\n",
        "    # Save summary\n",
        "    summary_df = pd.DataFrame([\n",
        "        {\n",
        "            \"file\": k,\n",
        "            \"accuracy\": v['accuracy'],\n",
        "            \"f1_macro\": v['f1_macro'],\n",
        "            \"f1_weighted\": v['f1_weighted']\n",
        "        } for k, v in all_results.items()\n",
        "    ])\n",
        "    summary_df.loc[len(summary_df)] = {\n",
        "        \"file\": \"AVERAGE\",\n",
        "        \"accuracy\": summary_df['accuracy'].mean(),\n",
        "        \"f1_macro\": summary_df['f1_macro'].mean(),\n",
        "        \"f1_weighted\": summary_df['f1_weighted'].mean()\n",
        "    }\n",
        "    summary_path = os.path.join(output_dir, \"evaluation_summary.csv\")\n",
        "    summary_df.to_csv(summary_path, index=False)\n",
        "\n",
        "    print(\"Evaluation complete!\")\n",
        "    print(summary_df)\n",
        "    return all_results\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    model_path = \"/content/drive/My Drive/COL867_Assignment2/application_classification.cnn.model\"\n",
        "    parquet_paths = [\n",
        "        \"/content/drive/My Drive/NetFound/Parquet_Part3/parquet_files/Netflix.pcap.parquet\",\n",
        "        # Add more if needed\n",
        "    ]\n",
        "    output_dir = \"/content/drive/My Drive/NetFound/Evaluation_Output\"\n",
        "\n",
        "    evaluate_all_parquets(model_path, parquet_paths, output_dir, label_map=ID_TO_APP)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "TRQQ2AYu8bTs",
        "outputId": "d2882bc4-5c68-4c04-de8e-f19cdc5d7178"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Netflix.pcap...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-00b8dbdafae8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0moutput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/My Drive/NetFound/Evaluation_Output\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0mevaluate_all_parquets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparquet_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mID_TO_APP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-00b8dbdafae8>\u001b[0m in \u001b[0;36mevaluate_all_parquets\u001b[0;34m(model_path, parquet_paths, output_dir, label_map)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Evaluating {file_name}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparquet_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0mall_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-00b8dbdafae8>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, parquet_path, batch_size, label_map)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparquet_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;34m\"\"\"Evaluate a model on a single parquet file.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_parquet_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparquet_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-00b8dbdafae8>\u001b[0m in \u001b[0;36mload_parquet_data\u001b[0;34m(parquet_path, max_samples)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_parquet_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparquet_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;34m\"\"\"Load features and labels from a parquet file.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparquet_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'app_label'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[0mcheck_dtype_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m     return impl.read(\n\u001b[0m\u001b[1;32m    668\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m         )\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             pa_table = self.api.parquet.read_table(\n\u001b[0m\u001b[1;32m    275\u001b[0m                 \u001b[0mpath_or_handle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyarrow/parquet/core.py\u001b[0m in \u001b[0;36mread_table\u001b[0;34m(source, columns, use_threads, schema, use_pandas_metadata, read_dictionary, memory_map, buffer_size, partitioning, filesystem, filters, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification)\u001b[0m\n\u001b[1;32m   1841\u001b[0m         )\n\u001b[1;32m   1842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1843\u001b[0;31m     return dataset.read(columns=columns, use_threads=use_threads,\n\u001b[0m\u001b[1;32m   1844\u001b[0m                         use_pandas_metadata=use_pandas_metadata)\n\u001b[1;32m   1845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyarrow/parquet/core.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, columns, use_threads, use_pandas_metadata)\u001b[0m\n\u001b[1;32m   1483\u001b[0m                 )\n\u001b[1;32m   1484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1485\u001b[0;31m         table = self._dataset.to_table(\n\u001b[0m\u001b[1;32m   1486\u001b[0m             \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filter_expression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m             \u001b[0muse_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_threads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyarrow.parquet as pq\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import ast\n",
        "from pathlib import Path\n",
        "import os\n",
        "import gc  # For garbage collection\n",
        "\n",
        "def read_parquet_in_batches(parquet_path, batch_size):\n",
        "    table = pq.read_table(parquet_path, columns=[\"feature\", \"app_label\"])\n",
        "    num_rows = table.num_rows\n",
        "    for start in range(0, num_rows, batch_size):\n",
        "        end = min(start + batch_size, num_rows)\n",
        "        batch = table.slice(start, end).to_pandas()\n",
        "        X = np.stack(batch[\"feature\"].values).astype(np.float32)\n",
        "        y = batch[\"app_label\"].to_numpy()\n",
        "        yield X, y\n",
        "\n",
        "# def predict_and_evaluate_streamed(model, parquet_path, batch_size=64, max_rows=None):\n",
        "#     y_true, y_pred = [], []\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for X_batch, y_batch in read_parquet_in_batches(parquet_path, batch_size, max_rows):\n",
        "#             inputs = torch.from_numpy(X_batch)  # Faster than torch.tensor\n",
        "#             outputs = model(inputs)\n",
        "#             preds = outputs.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "#             y_true.extend(y_batch)\n",
        "#             y_pred.extend(preds)\n",
        "\n",
        "def predict_and_evaluate_streamed(model, parquet_path, batch_size=64, max_rows=None):\n",
        "    \"\"\"Evaluate model on parquet data in streamed batches.\"\"\"\n",
        "    y_true, y_pred = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in read_parquet_in_batches(parquet_path, batch_size, max_rows):\n",
        "            inputs = torch.tensor(X_batch, dtype=torch.float32).unsqueeze(1)  # Add channel dimension\n",
        "            outputs = model(inputs)\n",
        "            preds = outputs.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "            y_true.extend(y_batch)\n",
        "            y_pred.extend(preds)\n",
        "\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    results = {\n",
        "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
        "        \"f1_macro\": f1_score(y_true, y_pred, average=\"macro\"),\n",
        "        \"f1_weighted\": f1_score(y_true, y_pred, average=\"weighted\"),\n",
        "        \"confusion_matrix\": confusion_matrix(y_true, y_pred),\n",
        "        \"classification_report\": classification_report(y_true, y_pred)\n",
        "    }\n",
        "\n",
        "    return results, y_true, y_pred\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm, labels, title, save_path):\n",
        "    annot = True if len(labels) <= 50 else False  # Avoid annotating huge matrices\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(cm, annot=annot, fmt='d', cmap='Blues',\n",
        "                xticklabels=labels, yticklabels=labels)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "def evaluate_parquet_files_streamed(model, parquet_paths, output_dir, label_map, batch_size=64):\n",
        "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
        "    all_results = []\n",
        "\n",
        "    for parquet_path in parquet_paths:\n",
        "        file_name = Path(parquet_path).stem\n",
        "        print(f\"\\nStreaming evaluation for {file_name}...\")\n",
        "        results = predict_and_evaluate_streamed(model, parquet_path, batch_size, max_rows=5000)\n",
        "\n",
        "        #results = predict_and_evaluate_streamed(model, parquet_path, batch_size)\n",
        "\n",
        "        print(f\"\\n{file_name} Accuracy: {results['accuracy']:.4f}\")\n",
        "        print(results[\"classification_report\"])\n",
        "\n",
        "        cm_path = os.path.join(output_dir, f\"{file_name}_confusion_matrix.png\")\n",
        "        labels = [label_map.get(i, str(i)) for i in range(len(label_map))]\n",
        "        plot_confusion_matrix(results[\"confusion_matrix\"], labels, f\"Confusion Matrix - {file_name}\", cm_path)\n",
        "\n",
        "        all_results.append({\n",
        "            \"file\": file_name,\n",
        "            \"accuracy\": results[\"accuracy\"],\n",
        "            \"f1_macro\": results[\"f1_macro\"],\n",
        "            \"f1_weighted\": results[\"f1_weighted\"]\n",
        "        })\n",
        "\n",
        "        # Release memory\n",
        "        del results\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    # Summary\n",
        "    df = pd.DataFrame(all_results)\n",
        "    df.loc[len(df)] = {\n",
        "        \"file\": \"AVERAGE\",\n",
        "        \"accuracy\": df[\"accuracy\"].mean(),\n",
        "        \"f1_macro\": df[\"f1_macro\"].mean(),\n",
        "        \"f1_weighted\": df[\"f1_weighted\"].mean()\n",
        "    }\n",
        "    df.to_csv(os.path.join(output_dir, \"streamed_evaluation_summary.csv\"), index=False)\n",
        "    print(df)\n",
        "    return df\n",
        "\n",
        "def read_parquet_in_batches(parquet_path, batch_size, max_rows=5000):\n",
        "    table = pq.read_table(parquet_path, columns=[\"feature\", \"app_label\"])\n",
        "    num_rows = min(table.num_rows, max_rows)\n",
        "    for start in range(0, num_rows, batch_size):\n",
        "        end = min(start + batch_size, num_rows)\n",
        "        batch = table.slice(start, end).to_pandas()\n",
        "        X = np.stack(batch[\"feature\"].apply(ast.literal_eval)).astype(np.float32)\n",
        "        y = batch[\"app_label\"].to_numpy()\n",
        "        yield X, y\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model_path = \"/content/drive/My Drive/COL867_Assignment2/application_classification.cnn.model\"\n",
        "    parquet_paths = [\n",
        "        \"/content/drive/My Drive/NetFound/Parquet_Part3/parquet_files/Netflix.pcap.parquet\"\n",
        "    ]\n",
        "    output_dir = \"/content/drive/My Drive/NetFound/Evaluation_Streamed\"\n",
        "\n",
        "    model = load_application_classification_cnn_model(model_path, gpu=False)\n",
        "    evaluate_parquet_files_streamed(model, parquet_paths, output_dir, label_map=ID_TO_APP, batch_size=64)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2x0gULQ9PhO",
        "outputId": "28951658-1355-4d42-8a6a-2340eab330da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Streaming evaluation for Netflix.pcap...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyarrow.parquet as pq\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import ast\n",
        "from pathlib import Path\n",
        "import os\n",
        "import gc  # For garbage collection\n",
        "\n",
        "def read_parquet_in_batches(parquet_path, batch_size, max_rows=10000):\n",
        "    table = pq.read_table(parquet_path, columns=[\"feature\", \"app_label\"])\n",
        "    num_rows = min(table.num_rows, max_rows)  # Limit to max_rows (10,000)\n",
        "    for start in range(0, num_rows, batch_size):\n",
        "        end = min(start + batch_size, num_rows)\n",
        "        batch = table.slice(start, end).to_pandas()\n",
        "        X = np.stack(batch[\"feature\"].apply(ast.literal_eval)).astype(np.float32)\n",
        "        y = batch[\"app_label\"].to_numpy()\n",
        "        yield X, y\n",
        "\n",
        "def predict_and_evaluate_streamed(model, parquet_path, batch_size=64, max_rows=10000):\n",
        "    \"\"\"Evaluate model on parquet data in streamed batches.\"\"\"\n",
        "    y_true, y_pred = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in read_parquet_in_batches(parquet_path, batch_size, max_rows):\n",
        "            inputs = torch.tensor(X_batch, dtype=torch.float32).unsqueeze(1)  # Add channel dimension\n",
        "            outputs = model(inputs)\n",
        "            preds = outputs.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "            y_true.extend(y_batch)\n",
        "            y_pred.extend(preds)\n",
        "\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    results = {\n",
        "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
        "        \"f1_macro\": f1_score(y_true, y_pred, average=\"macro\"),\n",
        "        \"f1_weighted\": f1_score(y_true, y_pred, average=\"weighted\"),\n",
        "        \"confusion_matrix\": confusion_matrix(y_true, y_pred),\n",
        "        \"classification_report\": classification_report(y_true, y_pred)\n",
        "    }\n",
        "\n",
        "    return results, y_true, y_pred\n",
        "\n",
        "def plot_confusion_matrix(cm, labels, title, save_path):\n",
        "    annot = True if len(labels) <= 50 else False  # Avoid annotating huge matrices\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(cm, annot=annot, fmt='d', cmap='Blues',\n",
        "                xticklabels=labels, yticklabels=labels)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "def evaluate_parquet_files_streamed(model, parquet_paths, output_dir, label_map, batch_size=64):\n",
        "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
        "    all_results = []\n",
        "\n",
        "    for parquet_path in parquet_paths:\n",
        "        file_name = Path(parquet_path).stem\n",
        "        print(f\"\\nStreaming evaluation for {file_name}...\")\n",
        "\n",
        "        # Process only first 10,000 rows\n",
        "        results = predict_and_evaluate_streamed(model, parquet_path, batch_size, max_rows=10000)\n",
        "\n",
        "        print(f\"\\n{file_name} Accuracy: {results['accuracy']:.4f}\")\n",
        "        print(results[\"classification_report\"])\n",
        "\n",
        "        cm_path = os.path.join(output_dir, f\"{file_name}_confusion_matrix.png\")\n",
        "        labels = [label_map.get(i, str(i)) for i in range(len(label_map))]\n",
        "        plot_confusion_matrix(results[\"confusion_matrix\"], labels, f\"Confusion Matrix - {file_name}\", cm_path)\n",
        "\n",
        "        all_results.append({\n",
        "            \"file\": file_name,\n",
        "            \"accuracy\": results[\"accuracy\"],\n",
        "            \"f1_macro\": results[\"f1_macro\"],\n",
        "            \"f1_weighted\": results[\"f1_weighted\"]\n",
        "        })\n",
        "\n",
        "        # Release memory\n",
        "        del results\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    # Summary\n",
        "    df = pd.DataFrame(all_results)\n",
        "    df.loc[len(df)] = {\n",
        "        \"file\": \"AVERAGE\",\n",
        "        \"accuracy\": df[\"accuracy\"].mean(),\n",
        "        \"f1_macro\": df[\"f1_macro\"].mean(),\n",
        "        \"f1_weighted\": df[\"f1_weighted\"].mean()\n",
        "    }\n",
        "    df.to_csv(os.path.join(output_dir, \"streamed_evaluation_summary.csv\"), index=False)\n",
        "    print(df)\n",
        "    return df\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model_path = \"/content/drive/My Drive/COL867_Assignment2/application_classification.cnn.model\"\n",
        "    parquet_paths = [\n",
        "        \"/content/drive/My Drive/NetFound/Parquet_Part3/parquet_files/Netflix.pcap.parquet\"\n",
        "    ]\n",
        "    output_dir = \"/content/drive/My Drive/NetFound/Evaluation_Streamed\"\n",
        "\n",
        "    model = load_application_classification_cnn_model(model_path, gpu=False)\n",
        "    evaluate_parquet_files_streamed(model, parquet_paths, output_dir, label_map=ID_TO_APP, batch_size=64)"
      ],
      "metadata": {
        "id": "-9mO9wVAJWfQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52bd2ff7-8c92-4815-9ac0-02c5f7f47765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Streaming evaluation for Netflix.pcap...\n"
          ]
        }
      ]
    }
  ]
}