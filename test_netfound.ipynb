{"cells":[{"cell_type":"markdown","metadata":{"id":"TOhMIvYr10Ej"},"source":["# Setup"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"eQQ9yoWb1-Y8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746680769103,"user_tz":-330,"elapsed":33975,"user":{"displayName":"Shiva","userId":"03583737290382297870"}},"outputId":"92a85c70-d895-45dc-af67-4d8e8c8ea8e1"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["cd /content/drive/MyDrive/COL867/NetFound/Shiva_Folder/netFound/src/train/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Kb64oBV2E55","executionInfo":{"status":"ok","timestamp":1746680771559,"user_tz":-330,"elapsed":2458,"user":{"displayName":"Shiva","userId":"03583737290382297870"}},"outputId":"dc693fc7-61f9-404e-dd1f-31ae661a7668"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/COL867/NetFound/Shiva_Folder/netFound/src/train\n"]}]},{"cell_type":"code","source":["!pip install datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l7aQSBNf3g89","executionInfo":{"status":"ok","timestamp":1746680775695,"user_tz":-330,"elapsed":4135,"user":{"displayName":"Shiva","userId":"03583737290382297870"}},"outputId":"0c9ebb7d-d908-4a46-c63f-1dd5a72fe00c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets)\n","  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n","  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2025.3.2\n","    Uninstalling fsspec-2025.3.2:\n","      Successfully uninstalled fsspec-2025.3.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-3.6.0 dill-0.3.8 fsspec-2025.3.0 multiprocess-0.70.16 xxhash-3.5.0\n"]}]},{"cell_type":"code","source":["!pip install torchinfo"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ceMofFWQ39-h","executionInfo":{"status":"ok","timestamp":1746680782045,"user_tz":-330,"elapsed":6349,"user":{"displayName":"Shiva","userId":"03583737290382297870"}},"outputId":"3bd90c77-65e6-4bd0-9c1a-0cd2d134c41a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchinfo\n","  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n","Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n","Installing collected packages: torchinfo\n","Successfully installed torchinfo-1.8.0\n"]}]},{"cell_type":"code","source":["!pip install tensorboard"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sNRJmdBqKT1v","executionInfo":{"status":"ok","timestamp":1746680786697,"user_tz":-330,"elapsed":4639,"user":{"displayName":"Shiva","userId":"03583737290382297870"}},"outputId":"44365f03-2c8e-40f6-be31-e6a15cc6f0e5"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.71.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.8)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (2.0.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard) (24.2)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (5.29.4)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.2.0)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n"]}]},{"cell_type":"code","execution_count":6,"metadata":{"id":"5yfR7hCF10Ek","executionInfo":{"status":"ok","timestamp":1746680819472,"user_tz":-330,"elapsed":32765,"user":{"displayName":"Shiva","userId":"03583737290382297870"}}},"outputs":[],"source":["import warnings\n","from sklearn.exceptions import UndefinedMetricWarning\n","warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n","warnings.filterwarnings(\"ignore\", category=FutureWarning)\n","\n","import os\n","import torch\n","import torch.distributed\n","import numpy as np\n","import utils\n","import random\n","from dataclasses import field, dataclass\n","from datasets.distributed import split_dataset_by_node\n","from typing import Optional\n","from copy import deepcopy\n","from torchinfo import summary\n","from torch.distributed.elastic.multiprocessing.errors import record\n","\n","from transformers import (\n","    EvalPrediction,\n","    HfArgumentParser,\n","    TrainingArguments,\n","    EarlyStoppingCallback,\n",")\n","\n","from sklearn.metrics import (\n","    f1_score,\n","    accuracy_score,\n","    precision_score,\n","    recall_score,\n","    top_k_accuracy_score,\n","    classification_report, confusion_matrix\n",")\n","\n","from NetFoundDataCollator import DataCollatorForFlowClassification\n","from NetFoundModels import NetfoundFinetuningModel, NetfoundNoPTM\n","from NetFoundTrainer import NetfoundTrainer\n","from NetfoundConfig import NetfoundConfig, NetFoundTCPOptionsConfig, NetFoundLarge\n","from NetfoundTokenizer import NetFoundTokenizer\n","\n","from utils import ModelArguments, CommonDataTrainingArguments, freeze, verify_checkpoint, \\\n","    load_train_test_datasets, get_90_percent_cpu_count, get_logger, init_tbwriter, update_deepspeed_config, \\\n","    LearningRateLogCallback\n","\n","random.seed(42)\n","logger = get_logger(name=__name__)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","source":["import torch.optim as optim\n","import torch.nn as nn\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report"],"metadata":{"id":"0Zmlaz8U7E41","executionInfo":{"status":"ok","timestamp":1746680819487,"user_tz":-330,"elapsed":13,"user":{"displayName":"Shiva","userId":"03583737290382297870"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CfMFQwqL10Em"},"source":["# Funtions"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"7TKdOZR310Em","executionInfo":{"status":"ok","timestamp":1746680819490,"user_tz":-330,"elapsed":1,"user":{"displayName":"Shiva","userId":"03583737290382297870"}}},"outputs":[],"source":["@dataclass\n","class FineTuningDataTrainingArguments(CommonDataTrainingArguments):\n","    \"\"\"\n","    Arguments pertaining to what data we are going to input our model for training and eval.\n","    \"\"\"\n","\n","    num_labels: int = field(metadata={\"help\": \"number of classes in the datasets\"}, default=None)\n","    problem_type: Optional[str] = field(\n","        default=None,\n","        metadata={\"help\": \"Override regression or classification task\"},\n","    )\n","    p_val: float = field(\n","        default=0,\n","        metadata={\n","            \"help\": \"noise rate\"\n","        },\n","    )\n","    netfound_large: bool = field(\n","        default=False,\n","        metadata={\n","            \"help\": \"Use the large configuration for netFound model\"\n","        },\n","    )"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"g44RY2-V10En","executionInfo":{"status":"ok","timestamp":1746680819495,"user_tz":-330,"elapsed":4,"user":{"displayName":"Shiva","userId":"03583737290382297870"}}},"outputs":[],"source":["def regression_metrics(p: EvalPrediction):\n","    logits = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n","    label_ids = p.label_ids.astype(int)\n","    return {\"loss\": np.mean(np.absolute((logits - label_ids)))}"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"lZCNLM2j10En","executionInfo":{"status":"ok","timestamp":1746680819503,"user_tz":-330,"elapsed":3,"user":{"displayName":"Shiva","userId":"03583737290382297870"}}},"outputs":[],"source":["def classif_metrics(p: EvalPrediction, num_classes):\n","    logits = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n","    label_ids = p.label_ids.astype(int)\n","    weighted_f1 = f1_score(\n","        y_true=label_ids, y_pred=logits.argmax(axis=1), average=\"weighted\", zero_division=0\n","    )\n","    weighted_prec = precision_score(\n","        y_true=label_ids, y_pred=logits.argmax(axis=1), average=\"weighted\", zero_division=0\n","    )\n","    weighted_recall = recall_score(\n","        y_true=label_ids, y_pred=logits.argmax(axis=1), average=\"weighted\", zero_division=0\n","    )\n","    accuracy = accuracy_score(y_true=label_ids, y_pred=logits.argmax(axis=1))\n","    logger.warning(classification_report(label_ids, logits.argmax(axis=1), digits=5))\n","    logger.warning(confusion_matrix(label_ids, logits.argmax(axis=1)))\n","    if num_classes > 3:\n","        logger.warning(f\"top3:{top_k_accuracy_score(label_ids, logits, k=3, labels=np.arange(num_classes))}\")\n","    if num_classes > 5:\n","        logger.warning(f\"top5:{top_k_accuracy_score(label_ids, logits, k=5, labels=np.arange(num_classes))}\")\n","    if num_classes > 10:\n","        logger.warning(f\"top10:{top_k_accuracy_score(label_ids, logits, k=10, labels=np.arange(num_classes))}\")\n","    return {\n","        \"weighted_f1\": weighted_f1,\n","        \"accuracy\": accuracy,\n","        \"weighted_prec: \": weighted_prec,\n","        \"weighted_recall\": weighted_recall,\n","    }"]},{"cell_type":"markdown","metadata":{"id":"J6lpW2rr10Eo"},"source":["# Load Model and Dataset"]},{"cell_type":"code","source":["dataset_folder = r\"/content/drive/MyDrive/COL867/NetFound/Shiva_Folder/netFound/data/test/test_finetuning/final/combined/\"\n","pretrained_model_path = r\"/content/drive/MyDrive/COL867/NetFound/Shiva_Folder/netFound/models/test/original_pretraining/pretrained_model/\"\n","output_dir = r\"/content/drive/MyDrive/COL867/NetFound/Shiva_Folder/netFound/models/test/seperate_finetuning/\""],"metadata":{"id":"KvVCcUhb4N52","executionInfo":{"status":"ok","timestamp":1746680819505,"user_tz":-330,"elapsed":1,"user":{"displayName":"Shiva","userId":"03583737290382297870"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","execution_count":12,"metadata":{"id":"_15I5z8p10Eo","executionInfo":{"status":"ok","timestamp":1746680819537,"user_tz":-330,"elapsed":20,"user":{"displayName":"Shiva","userId":"03583737290382297870"}}},"outputs":[],"source":["parser = HfArgumentParser((ModelArguments, FineTuningDataTrainingArguments, TrainingArguments))\n","model_args, data_args, training_args = parser.parse_args_into_dataclasses(args=[\"--train_dir\", dataset_folder, \"--test_dir\", dataset_folder, \"--model_name_or_path\", pretrained_model_path, \"--output_dir\", output_dir, \"--report_to\", \"tensorboard\", \"--overwrite_output_dir\", \"--save_safetensors\", \"false\", \"--do_train\", \"--do_eval\", \"--eval_strategy\", \"epoch\", \"--save_strategy\", \"epoch\", \"--learning_rate\", \"0.01\", \"--num_train_epochs\", \"1\", \"--problem_type\", \"single_label_classification\", \"--num_labels\", \"6\", \"--load_best_model_at_end\", \"--netfound_large\", \"True\"])\n","# utils.LOGGING_LEVEL = training_args.get_process_log_level()\n","utils.LOGGING_LEVEL = 10\n","logger.setLevel(10)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"Rav0fKQr10Ep","colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"status":"ok","timestamp":1746680819671,"user_tz":-330,"elapsed":106,"user":{"displayName":"Shiva","userId":"03583737290382297870"}},"outputId":"d2316864-ec49-4213-92e4-8ecc99cb67d2"},"outputs":[{"output_type":"stream","name":"stderr","text":["model_args: ModelArguments(model_name_or_path='/content/drive/MyDrive/COL867/NetFound/Shiva_Folder/netFound/models/test/original_pretraining/pretrained_model/', metaFeatures=4, num_hidden_layers=12, num_attention_heads=12, hidden_size=768, no_ptm=False, freeze_flow_encoder=False, freeze_burst_encoder=False, freeze_embeddings=False, freeze_base=False)\n","INFO:__main__:model_args: ModelArguments(model_name_or_path='/content/drive/MyDrive/COL867/NetFound/Shiva_Folder/netFound/models/test/original_pretraining/pretrained_model/', metaFeatures=4, num_hidden_layers=12, num_attention_heads=12, hidden_size=768, no_ptm=False, freeze_flow_encoder=False, freeze_burst_encoder=False, freeze_embeddings=False, freeze_base=False)\n","data_args: FineTuningDataTrainingArguments(train_dir='/content/drive/MyDrive/COL867/NetFound/Shiva_Folder/netFound/data/test/test_finetuning/final/combined/', test_dir='/content/drive/MyDrive/COL867/NetFound/Shiva_Folder/netFound/data/test/test_finetuning/final/combined/', no_meta=False, flat=False, limit_bursts=False, validation_dir=None, validation_split_percentage=30, data_cache_dir='/tmp', overwrite_cache=False, max_bursts=12, max_seq_length=1308, preprocessing_num_workers=None, max_train_samples=None, max_eval_samples=None, streaming=False, tcpoptions=False, num_labels=6, problem_type='single_label_classification', p_val=0, netfound_large=True)\n","INFO:__main__:data_args: FineTuningDataTrainingArguments(train_dir='/content/drive/MyDrive/COL867/NetFound/Shiva_Folder/netFound/data/test/test_finetuning/final/combined/', test_dir='/content/drive/MyDrive/COL867/NetFound/Shiva_Folder/netFound/data/test/test_finetuning/final/combined/', no_meta=False, flat=False, limit_bursts=False, validation_dir=None, validation_split_percentage=30, data_cache_dir='/tmp', overwrite_cache=False, max_bursts=12, max_seq_length=1308, preprocessing_num_workers=None, max_train_samples=None, max_eval_samples=None, streaming=False, tcpoptions=False, num_labels=6, problem_type='single_label_classification', p_val=0, netfound_large=True)\n","training_args: TrainingArguments(\n","_n_gpu=1,\n","accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","average_tokens_across_devices=False,\n","batch_eval_metrics=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_persistent_workers=False,\n","dataloader_pin_memory=True,\n","dataloader_prefetch_factor=None,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","do_eval=True,\n","do_predict=False,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_do_concat_batches=True,\n","eval_on_start=False,\n","eval_steps=None,\n","eval_strategy=IntervalStrategy.EPOCH,\n","eval_use_gather_object=False,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","gradient_checkpointing_kwargs=None,\n","greater_is_better=False,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=None,\n","hub_strategy=HubStrategy.EVERY_SAVE,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_for_metrics=[],\n","include_inputs_for_metrics=False,\n","include_num_input_tokens_seen=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=0.01,\n","length_column_name=length,\n","load_best_model_at_end=True,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=/content/drive/MyDrive/COL867/NetFound/Shiva_Folder/netFound/models/test/seperate_finetuning/runs/May08_05-07-00_75d137c545e6,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=IntervalStrategy.STEPS,\n","lr_scheduler_kwargs={},\n","lr_scheduler_type=SchedulerType.LINEAR,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=loss,\n","mp_parameters=,\n","neftune_noise_alpha=None,\n","no_cuda=False,\n","num_train_epochs=1.0,\n","optim=OptimizerNames.ADAMW_TORCH,\n","optim_args=None,\n","optim_target_modules=None,\n","output_dir=/content/drive/MyDrive/COL867/NetFound/Shiva_Folder/netFound/models/test/seperate_finetuning/,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=8,\n","per_device_train_batch_size=8,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard'],\n","restore_callback_states_from_checkpoint=False,\n","resume_from_checkpoint=None,\n","run_name=/content/drive/MyDrive/COL867/NetFound/Shiva_Folder/netFound/models/test/seperate_finetuning/,\n","save_on_each_node=False,\n","save_only_model=False,\n","save_safetensors=False,\n","save_steps=500,\n","save_strategy=SaveStrategy.EPOCH,\n","save_total_limit=None,\n","seed=42,\n","skip_memory_metrics=True,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torch_empty_cache_steps=None,\n","torchdynamo=None,\n","tp_size=0,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_liger_kernel=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","INFO:__main__:training_args: TrainingArguments(\n","_n_gpu=1,\n","accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","average_tokens_across_devices=False,\n","batch_eval_metrics=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_persistent_workers=False,\n","dataloader_pin_memory=True,\n","dataloader_prefetch_factor=None,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","do_eval=True,\n","do_predict=False,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_do_concat_batches=True,\n","eval_on_start=False,\n","eval_steps=None,\n","eval_strategy=IntervalStrategy.EPOCH,\n","eval_use_gather_object=False,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","gradient_checkpointing_kwargs=None,\n","greater_is_better=False,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=None,\n","hub_strategy=HubStrategy.EVERY_SAVE,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_for_metrics=[],\n","include_inputs_for_metrics=False,\n","include_num_input_tokens_seen=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=0.01,\n","length_column_name=length,\n","load_best_model_at_end=True,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=/content/drive/MyDrive/COL867/NetFound/Shiva_Folder/netFound/models/test/seperate_finetuning/runs/May08_05-07-00_75d137c545e6,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=IntervalStrategy.STEPS,\n","lr_scheduler_kwargs={},\n","lr_scheduler_type=SchedulerType.LINEAR,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=loss,\n","mp_parameters=,\n","neftune_noise_alpha=None,\n","no_cuda=False,\n","num_train_epochs=1.0,\n","optim=OptimizerNames.ADAMW_TORCH,\n","optim_args=None,\n","optim_target_modules=None,\n","output_dir=/content/drive/MyDrive/COL867/NetFound/Shiva_Folder/netFound/models/test/seperate_finetuning/,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=8,\n","per_device_train_batch_size=8,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard'],\n","restore_callback_states_from_checkpoint=False,\n","resume_from_checkpoint=None,\n","run_name=/content/drive/MyDrive/COL867/NetFound/Shiva_Folder/netFound/models/test/seperate_finetuning/,\n","save_on_each_node=False,\n","save_only_model=False,\n","save_safetensors=False,\n","save_steps=500,\n","save_strategy=SaveStrategy.EPOCH,\n","save_total_limit=None,\n","seed=42,\n","skip_memory_metrics=True,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torch_empty_cache_steps=None,\n","torchdynamo=None,\n","tp_size=0,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_liger_kernel=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n"]}],"source":["logger.info(f\"model_args: {model_args}\")\n","logger.info(f\"data_args: {data_args}\")\n","logger.info(f\"training_args: {training_args}\")"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"btGItctb10Ep","colab":{"base_uri":"https://localhost:8080/","height":0,"referenced_widgets":["b97e3290eb3c425fa1cfe3c1d73a8509","a89c73c2cce44f63a3f568dee6362dab","e9f190d768df42cab5c0c118e40d97c2","830127a3cee647eca484f3337d6c0ba0","7c69438a020344bf9b3fb21741186277","7f80fd54af384875979a6beec1923ad6","3f241c28568f4ad2911e993cb9f9ca5b","6b631f1c39a6415d87eb80db8bdccc4c","ac144506684f45cb8e7e21e5f6940d06","423743d0922d48fbb65095b4beb271eb","73f3610e994a4afcb4396a54ec2d5ebb"]},"executionInfo":{"status":"ok","timestamp":1746680829611,"user_tz":-330,"elapsed":9939,"user":{"displayName":"Shiva","userId":"03583737290382297870"}},"outputId":"38be8b8f-7c03-440f-cad3-ecad9264dfe2"},"outputs":[{"output_type":"stream","name":"stderr","text":["Loading datasets\n","WARNING:__main__:Loading datasets\n"]},{"output_type":"display_data","data":{"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b97e3290eb3c425fa1cfe3c1d73a8509"}},"metadata":{}}],"source":["train_dataset, test_dataset = load_train_test_datasets(logger, data_args)"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"NNGVlIHz10Ep","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746680829623,"user_tz":-330,"elapsed":11,"user":{"displayName":"Shiva","userId":"03583737290382297870"}},"outputId":"a7309ddb-599c-408d-99b4-91ee74407fc8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1803, 1803)"]},"metadata":{},"execution_count":15}],"source":["len(train_dataset), len(test_dataset)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"OYQHLVgk10Ep","executionInfo":{"status":"ok","timestamp":1746680829634,"user_tz":-330,"elapsed":2,"user":{"displayName":"Shiva","userId":"03583737290382297870"}}},"outputs":[],"source":["config = NetFoundTCPOptionsConfig if data_args.tcpoptions else NetfoundConfig"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"Clncjw7U10Eq","executionInfo":{"status":"ok","timestamp":1746680829649,"user_tz":-330,"elapsed":13,"user":{"displayName":"Shiva","userId":"03583737290382297870"}}},"outputs":[],"source":["config = config(num_hidden_layers=model_args.num_hidden_layers, num_attention_heads=model_args.num_attention_heads,\n","        hidden_size=model_args.hidden_size, no_meta=data_args.no_meta, flat=data_args.flat)"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"EQzMmXrU10Eq","executionInfo":{"status":"ok","timestamp":1746680829653,"user_tz":-330,"elapsed":2,"user":{"displayName":"Shiva","userId":"03583737290382297870"}}},"outputs":[],"source":["if data_args.netfound_large:\n","    config.hidden_size = NetFoundLarge().hidden_size\n","    config.num_hidden_layers = NetFoundLarge().num_hidden_layers\n","    config.num_attention_heads = NetFoundLarge().num_attention_heads"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"GfTtI1dQ10Eq","executionInfo":{"status":"ok","timestamp":1746680829703,"user_tz":-330,"elapsed":49,"user":{"displayName":"Shiva","userId":"03583737290382297870"}}},"outputs":[],"source":["config.pretraining = False\n","config.num_labels = data_args.num_labels\n","config.problem_type = data_args.problem_type\n","testingTokenizer = NetFoundTokenizer(config=config)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"UBW-b2Cq10Eq","executionInfo":{"status":"ok","timestamp":1746680829704,"user_tz":-330,"elapsed":7,"user":{"displayName":"Shiva","userId":"03583737290382297870"}}},"outputs":[],"source":["training_config = deepcopy(config)\n","training_config.p = data_args.p_val\n","training_config.limit_bursts = data_args.limit_bursts\n","trainingTokenizer = NetFoundTokenizer(config=training_config)\n","additionalFields = None"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"A08OQyN310Eq","executionInfo":{"status":"ok","timestamp":1746680829706,"user_tz":-330,"elapsed":7,"user":{"displayName":"Shiva","userId":"03583737290382297870"}}},"outputs":[],"source":["params = {\"batched\": True}"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"LZ-7e-HM10Eq","executionInfo":{"status":"ok","timestamp":1746680837160,"user_tz":-330,"elapsed":7460,"user":{"displayName":"Shiva","userId":"03583737290382297870"}},"colab":{"base_uri":"https://localhost:8080/","height":0,"referenced_widgets":["c8be958ba605448b8fa4d4dc0c01e30d","4d04e8fb12c14a8c9b4461b86a29aa35","ef1d64c996904e17b7d647daa01b6e24","e85761de758b415997db2ae63e81fe6a","d79a70eec91f408ab208fd9f847e8134","d90e8fb52ac4405f89baed05bd6d204e","a3ab5de959364ce8bb3148222017cc26","ed8b5bbbddab4d9486c2d5ca4c7b88f5","432850d9a68b49beae7101109ecd044f","45d4703696784361900428f548f37ecc","d15c1e1633a44e8485e318f3ab66dd70"]},"outputId":"00242d66-6f90-4026-89ea-05f059fc039d"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1803 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8be958ba605448b8fa4d4dc0c01e30d"}},"metadata":{}}],"source":["train_dataset = train_dataset.map(function=trainingTokenizer, **params)\n","test_dataset = test_dataset.map(function=testingTokenizer, **params)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"lzpoVxQ410Eq","executionInfo":{"status":"ok","timestamp":1746680837170,"user_tz":-330,"elapsed":6,"user":{"displayName":"Shiva","userId":"03583737290382297870"}}},"outputs":[],"source":["data_collator = DataCollatorForFlowClassification(config.max_burst_length)"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"W124ubNK10Er","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746680837183,"user_tz":-330,"elapsed":5,"user":{"displayName":"Shiva","userId":"03583737290382297870"}},"outputId":"03d980e9-016e-4aa8-e643-a2490932142b"},"outputs":[{"output_type":"stream","name":"stderr","text":["Using weights from /content/drive/MyDrive/COL867/NetFound/Shiva_Folder/netFound/models/test/original_pretraining/pretrained_model/\n","WARNING:__main__:Using weights from /content/drive/MyDrive/COL867/NetFound/Shiva_Folder/netFound/models/test/original_pretraining/pretrained_model/\n"]}],"source":["logger.warning(f\"Using weights from {model_args.model_name_or_path}\")"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"DFrZ-83W10Er","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746680881123,"user_tz":-330,"elapsed":43939,"user":{"displayName":"Shiva","userId":"03583737290382297870"}},"outputId":"ef665f4c-d0fb-4398-9b65-fe6748f84b19"},"outputs":[{"output_type":"stream","name":"stderr","text":["[WARNING|modeling_utils.py:4932] 2025-05-08 05:08:01,824 >> Some weights of NetfoundFinetuningModel were not initialized from the model checkpoint at /content/drive/MyDrive/COL867/NetFound/Shiva_Folder/netFound/models/test/original_pretraining/pretrained_model/ and are newly initialized: ['classifier.bias', 'classifier.weight', 'hiddenLayer.bias', 'hiddenLayer.weight', 'hiddenLayer2.bias', 'hiddenLayer2.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["original_model = NetfoundFinetuningModel.from_pretrained(model_args.model_name_or_path, config=config)"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"czvj5Dwe10Er","executionInfo":{"status":"ok","timestamp":1746680881131,"user_tz":-330,"elapsed":13,"user":{"displayName":"Shiva","userId":"03583737290382297870"}}},"outputs":[],"source":["model = freeze(original_model, model_args)"]},{"cell_type":"markdown","metadata":{"id":"iJzu_NGU10Er"},"source":["# Infer Model"]},{"cell_type":"code","source":["saved_weights = os.path.join(output_dir, f'model_epoch_latest.pth')"],"metadata":{"id":"pKraduuYSbgx","executionInfo":{"status":"ok","timestamp":1746680881256,"user_tz":-330,"elapsed":62,"user":{"displayName":"Shiva","userId":"03583737290382297870"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["weights = torch.load(saved_weights)\n","model.load_state_dict(weights)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Olg11atUSkvV","executionInfo":{"status":"ok","timestamp":1746680926324,"user_tz":-330,"elapsed":44965,"user":{"displayName":"Shiva","userId":"03583737290382297870"}},"outputId":"54fe7c39-528e-411b-f15a-8ad5b94c26b0"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","execution_count":29,"metadata":{"id":"oEf4QRQ710Er","executionInfo":{"status":"ok","timestamp":1746680926327,"user_tz":-330,"elapsed":4,"user":{"displayName":"Shiva","userId":"03583737290382297870"}}},"outputs":[],"source":["for x in train_dataset:\n","    break"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"c-vjy5yD10Er","executionInfo":{"status":"ok","timestamp":1746680926337,"user_tz":-330,"elapsed":9,"user":{"displayName":"Shiva","userId":"03583737290382297870"}}},"outputs":[],"source":["px = data_collator([x])"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"031euCgD10Er","executionInfo":{"status":"ok","timestamp":1746680927811,"user_tz":-330,"elapsed":1473,"user":{"displayName":"Shiva","userId":"03583737290382297870"}}},"outputs":[],"source":["py = model(labels = px['labels'], protocol = px['protocol'], flow_duration = px['flow_duration'], bytes = px['bytes'], iats = px['iats'], input_ids = px['input_ids'], attention_mask = px['attention_mask'], direction = px['direction'], pkt_count = px['pkt_count'])"]},{"cell_type":"code","source":["py.logits"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ybsMjn7-SqW2","executionInfo":{"status":"ok","timestamp":1746680927813,"user_tz":-330,"elapsed":5,"user":{"displayName":"Shiva","userId":"03583737290382297870"}},"outputId":"20afa0fb-7abe-45dd-8b94-a2eec567a4b8"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.0150, -0.1482,  0.2586,  0.0146, -0.0980, -0.1117]],\n","       grad_fn=<AddmmBackward0>)"]},"metadata":{},"execution_count":32}]},{"cell_type":"markdown","source":["# Train Model"],"metadata":{"id":"9mnxCQLY6dck"}},{"cell_type":"code","source":["model = model.to(device)"],"metadata":{"id":"ToEdkFdZ-jo8","executionInfo":{"status":"ok","timestamp":1746681082268,"user_tz":-330,"elapsed":735,"user":{"displayName":"Shiva","userId":"03583737290382297870"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ulnzq3ZzKMgf","executionInfo":{"status":"ok","timestamp":1746681082275,"user_tz":-330,"elapsed":5,"user":{"displayName":"Shiva","userId":"03583737290382297870"}},"outputId":"59e03687-f656-4f15-e393-f4860c0f3ff6"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["model = model.train()"],"metadata":{"id":"O2z-SHfd6eXn","executionInfo":{"status":"ok","timestamp":1746681082292,"user_tz":-330,"elapsed":16,"user":{"displayName":"Shiva","userId":"03583737290382297870"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["req_keys = ['labels', 'protocol', 'flow_duration', 'bytes', 'iats', 'input_ids', 'attention_mask', 'direction', 'pkt_count', 'total_bursts']"],"metadata":{"id":"i3QBhDltQ5qV","executionInfo":{"status":"ok","timestamp":1746681083239,"user_tz":-330,"elapsed":4,"user":{"displayName":"Shiva","userId":"03583737290382297870"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["for p in model.base_transformer.parameters():\n","    p.requires_grad = False\n","for p in model.attentivePooling.parameters():\n","    p.requires_grad = False\n","for p in model.dropout.parameters():\n","    p.requires_grad = True\n","for p in model.hiddenLayer.parameters():\n","    p.requires_grad = True\n","for p in model.hiddenLayer2.parameters():\n","    p.requires_grad = True\n","for p in model.classifier.parameters():\n","    p.requires_grad = True"],"metadata":{"id":"xskd7TkoDzpn","executionInfo":{"status":"ok","timestamp":1746681084053,"user_tz":-330,"elapsed":2,"user":{"displayName":"Shiva","userId":"03583737290382297870"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n","batch_size = 64"],"metadata":{"id":"TzB-cQrS635p","executionInfo":{"status":"ok","timestamp":1746681404841,"user_tz":-330,"elapsed":15,"user":{"displayName":"Shiva","userId":"03583737290382297870"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["train_len = len(train_dataset)\n","train_inds = np.arange(train_len)\n","np.random.shuffle(train_inds)\n","train_inds = train_inds.tolist()"],"metadata":{"id":"5ycJUIouWWPU","executionInfo":{"status":"ok","timestamp":1746681097878,"user_tz":-330,"elapsed":8,"user":{"displayName":"Shiva","userId":"03583737290382297870"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["xl = []\n","for i, ind in enumerate(train_inds):\n","  x = train_dataset[ind]\n","  if i%batch_size != batch_size - 1:\n","    xx = {k: x[k] for k in x if k in req_keys}\n","    xl.append(xx)\n","    continue\n","\n","  px = data_collator(xl)\n","  print(px['labels'])\n","  xl = []"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"MBdEJe4pTnl2","executionInfo":{"status":"ok","timestamp":1746681108667,"user_tz":-330,"elapsed":8738,"user":{"displayName":"Shiva","userId":"03583737290382297870"}},"outputId":"f26d43c4-6db3-4204-b8a5-249eb7fc05a9"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0, 1, 0, 3, 3, 1, 3, 4, 4, 2, 0, 2, 2, 4, 4])\n","tensor([3, 4, 3, 5, 5, 5, 2, 0, 0, 3, 2, 3, 1, 1, 1])\n","tensor([3, 0, 4, 4, 2, 2, 3, 0, 1, 3, 4, 5, 3, 4, 0])\n","tensor([5, 2, 4, 5, 4, 2, 3, 1, 2, 1, 0, 3, 2, 2, 0])\n","tensor([0, 0, 2, 1, 2, 5, 4, 5, 1, 5, 0, 4, 4, 1, 4])\n","tensor([0, 3, 4, 5, 3, 4, 4, 5, 3, 3, 2, 3, 3, 0, 3])\n","tensor([1, 2, 1, 0, 1, 3, 0, 1, 0, 5, 1, 1, 4, 4, 3])\n","tensor([0, 2, 1, 5, 5, 1, 2, 1, 1, 0, 3, 5, 4, 0, 0])\n","tensor([1, 4, 2, 3, 5, 3, 2, 1, 4, 3, 5, 0, 4, 3, 2])\n","tensor([0, 2, 5, 4, 0, 3, 3, 2, 2, 4, 4, 4, 2, 0, 4])\n","tensor([3, 5, 3, 5, 2, 4, 2, 0, 2, 5, 1, 1, 0, 2, 5])\n","tensor([4, 3, 3, 2, 4, 3, 4, 1, 5, 4, 2, 5, 5, 4, 2])\n","tensor([2, 5, 5, 5, 4, 2, 5, 0, 5, 4, 3, 2, 3, 0, 5])\n","tensor([1, 1, 5, 4, 1, 1, 3, 3, 4, 1, 0, 3, 1, 2, 1])\n","tensor([1, 2, 3, 0, 5, 3, 3, 1, 4, 0, 2, 2, 1, 3, 5])\n","tensor([0, 0, 1, 1, 0, 4, 2, 0, 5, 5, 0, 4, 0, 3, 2])\n","tensor([2, 1, 1, 5, 2, 2, 4, 1, 1, 5, 2, 3, 4, 1, 2])\n","tensor([2, 1, 2, 1, 3, 4, 3, 4, 4, 2, 5, 5, 5, 2, 3])\n","tensor([4, 5, 4, 0, 2, 3, 1, 2, 1, 5, 3, 3, 2, 2, 1])\n","tensor([5, 4, 4, 1, 5, 4, 3, 4, 3, 5, 2, 4, 0, 2, 3])\n","tensor([5, 2, 2, 0, 1, 5, 2, 2, 3, 0, 0, 4, 3, 0, 4])\n","tensor([5, 4, 1, 4, 0, 5, 1, 1, 0, 2, 0, 1, 1, 1, 1])\n","tensor([5, 0, 4, 0, 0, 2, 1, 2, 3, 3, 2, 5, 5, 2, 3])\n","tensor([4, 0, 3, 2, 0, 1, 4, 2, 0, 4, 0, 1, 0, 0, 3])\n","tensor([5, 3, 3, 5, 1, 4, 4, 5, 2, 3, 1, 4, 2, 5, 0])\n","tensor([1, 2, 4, 2, 5, 0, 1, 5, 2, 3, 0, 5, 3, 2, 3])\n","tensor([1, 3, 1, 2, 5, 0, 1, 3, 5, 4, 5, 1, 0, 4, 3])\n","tensor([5, 2, 4, 4, 5, 5, 3, 5, 3, 4, 5, 0, 4, 3, 3])\n","tensor([4, 4, 2, 4, 0, 5, 0, 4, 1, 0, 0, 2, 5, 1, 5])\n","tensor([1, 1, 1, 4, 4, 4, 3, 5, 0, 0, 0, 0, 0, 4, 3])\n","tensor([1, 3, 4, 5, 2, 4, 2, 3, 5, 2, 4, 4, 0, 2, 4])\n","tensor([4, 1, 3, 5, 0, 4, 4, 1, 2, 4, 0, 5, 1, 1, 5])\n","tensor([1, 2, 0, 0, 0, 4, 5, 4, 0, 2, 1, 5, 2, 1, 4])\n","tensor([3, 5, 5, 0, 2, 1, 3, 5, 2, 3, 2, 1, 0, 5, 1])\n","tensor([0, 3, 1, 4, 5, 5, 5, 0, 0, 5, 4, 0, 2, 3, 2])\n","tensor([3, 4, 2, 2, 2, 5, 5, 5, 5, 5, 5, 1, 4, 5, 4])\n","tensor([2, 2, 3, 5, 5, 0, 0, 4, 3, 1, 1, 2, 2, 4, 2])\n","tensor([5, 3, 0, 1, 5, 2, 5, 2, 4, 3, 5, 1, 5, 2, 4])\n","tensor([1, 2, 0, 4, 3, 3, 1, 2, 2, 1, 2, 2, 1, 0, 1])\n","tensor([4, 1, 1, 4, 5, 0, 3, 4, 5, 5, 3, 2, 2, 2, 1])\n","tensor([3, 2, 3, 0, 4, 1, 5, 2, 1, 1, 2, 2, 1, 5, 2])\n","tensor([2, 5, 4, 4, 0, 0, 3, 4, 5, 4, 3, 3, 4, 2, 4])\n","tensor([0, 1, 3, 1, 0, 2, 1, 1, 5, 1, 2, 1, 4, 5, 2])\n","tensor([2, 5, 5, 5, 3, 0, 4, 1, 5, 0, 5, 0, 4, 4, 2])\n","tensor([1, 5, 4, 1, 5, 4, 4, 3, 2, 2, 4, 0, 4, 5, 0])\n","tensor([5, 2, 1, 2, 4, 3, 2, 5, 0, 2, 1, 2, 5, 4, 2])\n","tensor([0, 2, 0, 1, 2, 4, 1, 4, 0, 5, 5, 5, 3, 2, 1])\n","tensor([5, 2, 4, 0, 4, 1, 5, 5, 1, 1, 2, 4, 3, 0, 1])\n","tensor([3, 1, 4, 1, 1, 3, 2, 1, 0, 2, 0, 2, 1, 1, 0])\n","tensor([1, 0, 2, 2, 1, 0, 1, 5, 4, 5, 0, 5, 5, 4, 1])\n","tensor([3, 2, 0, 0, 4, 3, 0, 1, 0, 1, 3, 5, 3, 1, 5])\n","tensor([3, 3, 3, 4, 3, 2, 5, 0, 4, 5, 0, 5, 0, 0, 2])\n","tensor([5, 3, 5, 1, 5, 4, 4, 3, 1, 3, 0, 3, 2, 4, 5])\n","tensor([5, 2, 2, 2, 1, 0, 3, 2, 2, 0, 5, 3, 2, 4, 4])\n","tensor([1, 4, 4, 4, 4, 2, 2, 3, 2, 1, 5, 2, 1, 2, 0])\n","tensor([5, 5, 4, 3, 3, 4, 1, 4, 2, 5, 5, 1, 0, 3, 2])\n","tensor([5, 5, 3, 3, 1, 2, 2, 0, 1, 4, 4, 0, 4, 5, 1])\n","tensor([0, 3, 4, 5, 0, 5, 2, 2, 4, 0, 3, 1, 0, 5, 2])\n","tensor([5, 0, 1, 2, 5, 3, 4, 5, 1, 3, 3, 2, 5, 4, 2])\n","tensor([1, 3, 1, 2, 2, 2, 5, 5, 5, 1, 5, 0, 2, 5, 1])\n","tensor([4, 0, 0, 0, 4, 3, 5, 4, 5, 1, 4, 4, 5, 5, 4])\n","tensor([4, 4, 1, 0, 0, 4, 2, 0, 2, 4, 0, 3, 4, 5, 4])\n","tensor([5, 1, 5, 0, 2, 3, 2, 4, 2, 3, 4, 4, 2, 0, 1])\n","tensor([2, 5, 4, 4, 2, 0, 4, 1, 4, 3, 0, 0, 3, 1, 0])\n","tensor([0, 3, 0, 1, 1, 3, 5, 0, 4, 1, 4, 0, 1, 3, 2])\n","tensor([1, 3, 4, 2, 3, 4, 0, 3, 0, 0, 1, 4, 0, 3, 3])\n","tensor([2, 4, 1, 3, 3, 1, 1, 2, 5, 0, 2, 2, 4, 1, 4])\n","tensor([1, 3, 3, 0, 0, 1, 3, 3, 1, 0, 5, 0, 2, 1, 0])\n","tensor([1, 5, 4, 5, 4, 5, 4, 0, 4, 3, 3, 4, 0, 1, 5])\n","tensor([5, 4, 5, 0, 5, 0, 2, 4, 3, 5, 2, 0, 2, 2, 1])\n","tensor([1, 1, 2, 5, 4, 4, 2, 2, 4, 2, 5, 4, 4, 3, 4])\n","tensor([2, 0, 4, 0, 5, 3, 3, 4, 1, 0, 0, 5, 3, 0, 1])\n","tensor([4, 4, 4, 3, 1, 2, 2, 5, 4, 4, 0, 1, 2, 1, 3])\n","tensor([0, 1, 1, 3, 5, 2, 4, 1, 5, 0, 5, 5, 0, 3, 4])\n","tensor([5, 1, 2, 0, 1, 0, 0, 5, 3, 1, 0, 0, 3, 3, 4])\n","tensor([4, 0, 5, 5, 3, 5, 1, 0, 4, 1, 4, 1, 2, 3, 1])\n","tensor([1, 0, 3, 2, 3, 5, 3, 4, 5, 2, 2, 3, 2, 0, 0])\n","tensor([2, 0, 4, 1, 1, 2, 5, 1, 1, 5, 5, 3, 3, 3, 5])\n","tensor([5, 1, 2, 3, 1, 0, 1, 2, 4, 2, 4, 3, 4, 4, 1])\n","tensor([2, 4, 1, 1, 1, 4, 4, 4, 4, 3, 1, 4, 1, 2, 2])\n","tensor([0, 0, 2, 0, 2, 1, 2, 2, 0, 3, 5, 1, 0, 5, 1])\n","tensor([5, 2, 2, 2, 0, 0, 5, 0, 1, 2, 3, 5, 4, 4, 2])\n","tensor([0, 3, 4, 5, 0, 3, 0, 5, 2, 5, 1, 2, 5, 2, 1])\n","tensor([4, 1, 1, 0, 2, 3, 0, 0, 2, 0, 1, 1, 2, 1, 5])\n","tensor([0, 0, 5, 5, 2, 2, 0, 1, 5, 3, 5, 0, 5, 1, 3])\n","tensor([4, 1, 0, 2, 3, 0, 5, 5, 0, 0, 2, 0, 1, 4, 0])\n","tensor([3, 3, 2, 3, 3, 2, 2, 2, 3, 3, 1, 2, 1, 0, 2])\n","tensor([3, 1, 1, 3, 5, 3, 2, 2, 3, 5, 3, 0, 3, 5, 1])\n","tensor([3, 2, 3, 0, 0, 5, 4, 1, 5, 2, 2, 1, 4, 3, 0])\n","tensor([0, 0, 0, 1, 1, 1, 1, 2, 4, 5, 1, 0, 2, 1, 0])\n","tensor([1, 2, 2, 0, 4, 1, 1, 3, 0, 1, 5, 4, 1, 4, 3])\n","tensor([2, 0, 3, 3, 1, 0, 2, 0, 3, 0, 2, 0, 4, 4, 5])\n","tensor([0, 5, 3, 0, 5, 0, 2, 3, 1, 4, 0, 2, 4, 5, 1])\n","tensor([2, 4, 0, 2, 3, 4, 5, 5, 2, 0, 2, 2, 3, 3, 4])\n","tensor([4, 5, 3, 4, 4, 3, 5, 1, 4, 3, 5, 0, 2, 0, 2])\n","tensor([5, 0, 2, 2, 3, 5, 5, 3, 5, 5, 3, 3, 0, 5, 1])\n","tensor([2, 3, 0, 2, 1, 2, 5, 3, 1, 3, 5, 3, 3, 1, 5])\n","tensor([4, 2, 0, 1, 4, 1, 3, 3, 1, 5, 4, 5, 2, 1, 5])\n","tensor([3, 2, 2, 3, 5, 1, 4, 4, 2, 2, 1, 0, 0, 4, 0])\n","tensor([0, 2, 1, 3, 2, 0, 2, 4, 4, 5, 3, 3, 3, 1, 0])\n","tensor([4, 4, 4, 1, 1, 4, 0, 5, 3, 1, 0, 0, 0, 5, 1])\n","tensor([2, 3, 2, 4, 2, 0, 5, 2, 2, 3, 2, 5, 0, 4, 3])\n","tensor([3, 0, 2, 2, 3, 5, 2, 2, 4, 5, 2, 3, 0, 5, 4])\n","tensor([4, 4, 3, 4, 5, 5, 4, 2, 3, 3, 0, 3, 4, 0, 4])\n","tensor([3, 5, 3, 4, 0, 1, 4, 2, 2, 1, 4, 2, 3, 1, 5])\n","tensor([4, 5, 3, 2, 4, 3, 3, 5, 0, 3, 2, 1, 5, 2, 1])\n","tensor([0, 3, 0, 2, 3, 1, 3, 3, 4, 2, 3, 1, 1, 0, 5])\n","tensor([2, 3, 5, 5, 4, 0, 2, 3, 2, 5, 5, 2, 1, 4, 5])\n","tensor([1, 0, 2, 5, 4, 5, 2, 3, 3, 0, 5, 0, 4, 5, 3])\n","tensor([0, 1, 4, 2, 5, 5, 5, 5, 5, 1, 5, 2, 2, 1, 4])\n","tensor([3, 1, 5, 4, 0, 2, 3, 1, 0, 0, 4, 4, 3, 3, 0])\n","tensor([4, 0, 5, 2, 5, 1, 2, 0, 3, 2, 3, 3, 5, 1, 1])\n"]}]},{"cell_type":"code","source":["# py = model(labels = px['labels'], protocol = px['protocol'], flow_duration = px['flow_duration'], bytes = px['bytes'], iats = px['iats'], input_ids = px['input_ids'], attention_mask = px['attention_mask'], direction = px['direction'], pkt_count = px['pkt_count'])\n","# loss = criterion(py.logits, px['labels'])\n","# loss.backward()\n","# optimizer.step()"],"metadata":{"id":"FSB3RlgRT-z3","executionInfo":{"status":"ok","timestamp":1746681118107,"user_tz":-330,"elapsed":7,"user":{"displayName":"Shiva","userId":"03583737290382297870"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["for epoch in range(1):  # loop over the dataset multiple times\n","    running_loss = 0.0\n","    running_count = 0\n","    xl = []\n","    # for i, x in enumerate(train_dataset, 0):\n","    for i, ind in enumerate(train_inds, 0):\n","      x = train_dataset[ind]\n","      try:\n","        # get the inputs; data is a list of [inputs, labels]\n","        if i%batch_size != batch_size - 1:\n","          xx = {k: x[k] for k in x if k in req_keys}\n","          xl.append(xx)\n","          continue\n","\n","        px = data_collator(xl)\n","        px = {a: b.to(device) for a,b in px.items()}\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        py = model(labels = px['labels'], protocol = px['protocol'], flow_duration = px['flow_duration'], bytes = px['bytes'], iats = px['iats'],\n","                   input_ids = px['input_ids'], attention_mask = px['attention_mask'], direction = px['direction'], pkt_count = px['pkt_count'])\n","        loss = criterion(py.logits, px['labels'])\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print statistics\n","        running_loss += loss.item()\n","        running_count += 1\n","        xl = []\n","        # if i % (batch_size - 1)*10 == 9:\n","        print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / running_count:.3f} loss count: {running_count}')\n","        running_loss = 0.0\n","        running_count = 0\n","      except Exception as e:\n","        print(i, e)\n","        break\n","\n","print('Finished Training')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"pcMwmUxX632T","executionInfo":{"status":"ok","timestamp":1746651619488,"user_tz":-330,"elapsed":229257,"user":{"displayName":"Shiva","userId":"03583737290382297870"}},"outputId":"51df087c-68f3-4894-eead-2c0f17cbf914"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1,    16] loss: 1.766 loss count: 1\n","[1,    32] loss: 1.791 loss count: 1\n","[1,    48] loss: 1.831 loss count: 1\n","[1,    64] loss: 1.831 loss count: 1\n","[1,    80] loss: 1.773 loss count: 1\n","[1,    96] loss: 1.774 loss count: 1\n","[1,   112] loss: 1.796 loss count: 1\n","[1,   128] loss: 1.791 loss count: 1\n","[1,   144] loss: 1.714 loss count: 1\n","[1,   160] loss: 1.863 loss count: 1\n","[1,   176] loss: 1.842 loss count: 1\n","[1,   192] loss: 1.771 loss count: 1\n","[1,   208] loss: 1.774 loss count: 1\n","[1,   224] loss: 1.698 loss count: 1\n","[1,   240] loss: 1.817 loss count: 1\n","[1,   256] loss: 1.809 loss count: 1\n","[1,   272] loss: 1.792 loss count: 1\n","[1,   288] loss: 1.748 loss count: 1\n","[1,   304] loss: 1.798 loss count: 1\n","[1,   320] loss: 1.864 loss count: 1\n","[1,   336] loss: 1.856 loss count: 1\n","[1,   352] loss: 1.793 loss count: 1\n","[1,   368] loss: 1.848 loss count: 1\n","[1,   384] loss: 1.815 loss count: 1\n","[1,   400] loss: 1.740 loss count: 1\n","[1,   416] loss: 1.816 loss count: 1\n","[1,   432] loss: 1.819 loss count: 1\n","[1,   448] loss: 1.809 loss count: 1\n","[1,   464] loss: 1.790 loss count: 1\n","[1,   480] loss: 1.778 loss count: 1\n","[1,   496] loss: 1.774 loss count: 1\n","[1,   512] loss: 1.781 loss count: 1\n","[1,   528] loss: 1.779 loss count: 1\n","[1,   544] loss: 1.764 loss count: 1\n","[1,   560] loss: 1.798 loss count: 1\n","[1,   576] loss: 1.799 loss count: 1\n","[1,   592] loss: 1.797 loss count: 1\n","[1,   608] loss: 1.738 loss count: 1\n","[1,   624] loss: 1.753 loss count: 1\n","[1,   640] loss: 1.793 loss count: 1\n","[1,   656] loss: 1.730 loss count: 1\n","[1,   672] loss: 1.817 loss count: 1\n","[1,   688] loss: 1.801 loss count: 1\n","[1,   704] loss: 1.805 loss count: 1\n","[1,   720] loss: 1.815 loss count: 1\n","[1,   736] loss: 1.776 loss count: 1\n","[1,   752] loss: 1.812 loss count: 1\n","[1,   768] loss: 1.776 loss count: 1\n","[1,   784] loss: 1.845 loss count: 1\n","[1,   800] loss: 1.776 loss count: 1\n","[1,   816] loss: 1.784 loss count: 1\n","[1,   832] loss: 1.814 loss count: 1\n","[1,   848] loss: 1.796 loss count: 1\n","[1,   864] loss: 1.801 loss count: 1\n","[1,   880] loss: 1.793 loss count: 1\n","[1,   896] loss: 1.835 loss count: 1\n","[1,   912] loss: 1.812 loss count: 1\n","[1,   928] loss: 1.757 loss count: 1\n","[1,   944] loss: 1.764 loss count: 1\n","[1,   960] loss: 1.788 loss count: 1\n","[1,   976] loss: 1.812 loss count: 1\n","[1,   992] loss: 1.780 loss count: 1\n","[1,  1008] loss: 1.779 loss count: 1\n","[1,  1024] loss: 1.796 loss count: 1\n","[1,  1040] loss: 1.825 loss count: 1\n","[1,  1056] loss: 1.774 loss count: 1\n","[1,  1072] loss: 1.819 loss count: 1\n","[1,  1088] loss: 1.792 loss count: 1\n","[1,  1104] loss: 1.793 loss count: 1\n","[1,  1120] loss: 1.840 loss count: 1\n","[1,  1136] loss: 1.823 loss count: 1\n","[1,  1152] loss: 1.822 loss count: 1\n","[1,  1168] loss: 1.789 loss count: 1\n","[1,  1184] loss: 1.824 loss count: 1\n","[1,  1200] loss: 1.776 loss count: 1\n","[1,  1216] loss: 1.812 loss count: 1\n","[1,  1232] loss: 1.792 loss count: 1\n","[1,  1248] loss: 1.798 loss count: 1\n","[1,  1264] loss: 1.785 loss count: 1\n","[1,  1280] loss: 1.808 loss count: 1\n","[1,  1296] loss: 1.785 loss count: 1\n","[1,  1312] loss: 1.790 loss count: 1\n","[1,  1328] loss: 1.764 loss count: 1\n","[1,  1344] loss: 1.810 loss count: 1\n","[1,  1360] loss: 1.788 loss count: 1\n","[1,  1376] loss: 1.814 loss count: 1\n","[1,  1392] loss: 1.795 loss count: 1\n","[1,  1408] loss: 1.789 loss count: 1\n","[1,  1424] loss: 1.819 loss count: 1\n","[1,  1440] loss: 1.791 loss count: 1\n","[1,  1456] loss: 1.791 loss count: 1\n","[1,  1472] loss: 1.801 loss count: 1\n","[1,  1488] loss: 1.767 loss count: 1\n","[1,  1504] loss: 1.792 loss count: 1\n","[1,  1520] loss: 1.805 loss count: 1\n","[1,  1536] loss: 1.810 loss count: 1\n","[1,  1552] loss: 1.787 loss count: 1\n","[1,  1568] loss: 1.766 loss count: 1\n","[1,  1584] loss: 1.812 loss count: 1\n","[1,  1600] loss: 1.791 loss count: 1\n","[1,  1616] loss: 1.785 loss count: 1\n","[1,  1632] loss: 1.779 loss count: 1\n","[1,  1648] loss: 1.783 loss count: 1\n","[1,  1664] loss: 1.839 loss count: 1\n","[1,  1680] loss: 1.775 loss count: 1\n","[1,  1696] loss: 1.793 loss count: 1\n","[1,  1712] loss: 1.814 loss count: 1\n","[1,  1728] loss: 1.774 loss count: 1\n","[1,  1744] loss: 1.793 loss count: 1\n","[1,  1760] loss: 1.811 loss count: 1\n","[1,  1776] loss: 1.805 loss count: 1\n","[1,  1792] loss: 1.778 loss count: 1\n","Finished Training\n"]}]},{"cell_type":"code","source":["ground_truths = []\n","predictions = []\n","# since we're not training, we don't need to calculate the gradients for our outputs\n","xl = []\n","with torch.no_grad():\n","    for i, x in enumerate(test_dataset, 0):\n","      try:\n","        # get the inputs; data is a list of [inputs, labels]\n","        if i%batch_size != batch_size - 1:\n","          xx = {k: x[k] for k in x if k in req_keys}\n","          xl.append(xx)\n","          continue\n","\n","        px = data_collator(xl)\n","        px = {a: b.to(device) for a,b in px.items()}\n","\n","        # forward + backward + optimize\n","        py = model(labels = px['labels'], protocol = px['protocol'], flow_duration = px['flow_duration'], bytes = px['bytes'], iats = px['iats'],\n","                   input_ids = px['input_ids'], attention_mask = px['attention_mask'], direction = px['direction'], pkt_count = px['pkt_count'])\n","        # the class with the highest energy is what we choose as prediction\n","        labels = px['labels']\n","        outputs = py.logits\n","        _, predicted = torch.max(outputs, 1)\n","        ground_truths += labels.cpu().numpy().tolist()\n","        predictions += predicted.cpu().numpy().tolist()\n","        xl = []\n","      except Exception as e:\n","        print(i, e)\n","        pass\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(ground_truths, predictions)\n","print('Accuracy: %.3f' % accuracy)\n","\n","# Calculate precision\n","precision = precision_score(ground_truths, predictions, average='weighted')\n","print('Precision: %.3f' % precision)\n","\n","# Calculate recall\n","recall = recall_score(ground_truths, predictions, average='weighted')\n","print('Recall: %.3f' % recall)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5yjxcdQe63zO","executionInfo":{"status":"ok","timestamp":1746681380300,"user_tz":-330,"elapsed":201906,"user":{"displayName":"Shiva","userId":"03583737290382297870"}},"outputId":"70eb61b6-f755-4a8f-8628-b073feb32899"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.188\n","Precision: 0.316\n","Recall: 0.188\n"]}]},{"cell_type":"code","source":["print(classification_report(ground_truths, predictions, target_names=['0', '1', '2', '3', '4', '5']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h1uygNhgcKKA","executionInfo":{"status":"ok","timestamp":1746681380301,"user_tz":-330,"elapsed":8,"user":{"displayName":"Shiva","userId":"03583737290382297870"}},"outputId":"c440c3c6-6c7a-40ad-8e8a-34898558bed6"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.20      0.06      0.10       274\n","           1       0.21      0.01      0.03       274\n","           2       0.18      0.93      0.30       294\n","           3       0.20      0.05      0.08       269\n","           4       0.50      0.00      0.01       285\n","           5       0.58      0.02      0.05       284\n","\n","    accuracy                           0.19      1680\n","   macro avg       0.31      0.18      0.09      1680\n","weighted avg       0.32      0.19      0.09      1680\n","\n"]}]},{"cell_type":"code","source":["# torch.save(model.state_dict(), os.path.join(output_dir, 'model_epoch_0.pth'))"],"metadata":{"id":"UHn6fF9sIVlt","executionInfo":{"status":"ok","timestamp":1746681380302,"user_tz":-330,"elapsed":4,"user":{"displayName":"Shiva","userId":"03583737290382297870"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["prev_accuracy = accuracy"],"metadata":{"id":"CTCNBHfuIvsn","executionInfo":{"status":"ok","timestamp":1746681380328,"user_tz":-330,"elapsed":3,"user":{"displayName":"Shiva","userId":"03583737290382297870"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["for epoch in range(1, 50):  # loop over the dataset multiple times\n","    running_loss = 0.0\n","    running_count = 0\n","    xl = []\n","    # for i, x in enumerate(train_dataset, 0):\n","    for i, ind in enumerate(train_inds, 0):\n","      x = train_dataset[ind]\n","      try:\n","        # get the inputs; data is a list of [inputs, labels]\n","        if i%batch_size != batch_size - 1:\n","          xx = {k: x[k] for k in x if k in req_keys}\n","          xl.append(xx)\n","          continue\n","\n","        px = data_collator(xl)\n","        px = {a: b.to(device) for a,b in px.items()}\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        py = model(labels = px['labels'], protocol = px['protocol'], flow_duration = px['flow_duration'], bytes = px['bytes'], iats = px['iats'],\n","                   input_ids = px['input_ids'], attention_mask = px['attention_mask'], direction = px['direction'], pkt_count = px['pkt_count'])\n","        loss = criterion(py.logits, px['labels'])\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print statistics\n","        running_loss += loss.item()\n","        running_count += 1\n","        xl = []\n","        # if i % (batch_size - 1)*10 == 9:\n","      except Exception as e:\n","        print(i, e)\n","        break\n","    print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / running_count:.3f} loss count: {running_count}')\n","\n","    ground_truths = []\n","    predictions = []\n","    # since we're not training, we don't need to calculate the gradients for our outputs\n","    xl = []\n","    with torch.no_grad():\n","        for i, x in enumerate(test_dataset, 0):\n","          try:\n","            # get the inputs; data is a list of [inputs, labels]\n","            if i%batch_size != batch_size - 1:\n","              xx = {k: x[k] for k in x if k in req_keys}\n","              xl.append(xx)\n","              continue\n","\n","            px = data_collator(xl)\n","            px = {a: b.to(device) for a,b in px.items()}\n","\n","            # forward + backward + optimize\n","            py = model(labels = px['labels'], protocol = px['protocol'], flow_duration = px['flow_duration'], bytes = px['bytes'], iats = px['iats'],\n","                      input_ids = px['input_ids'], attention_mask = px['attention_mask'], direction = px['direction'], pkt_count = px['pkt_count'])\n","            # the class with the highest energy is what we choose as prediction\n","            labels = px['labels']\n","            outputs = py.logits\n","            _, predicted = torch.max(outputs, 1)\n","            ground_truths += labels.cpu().numpy().tolist()\n","            predictions += predicted.cpu().numpy().tolist()\n","            xl = []\n","          except Exception as e:\n","            print(i, e)\n","            pass\n","\n","    # Calculate accuracy\n","    accuracy = accuracy_score(ground_truths, predictions)\n","    print('Epoch: %d, Accuracy: %.3f' % (epoch, accuracy))\n","\n","    # Calculate precision\n","    precision = precision_score(ground_truths, predictions, average='weighted')\n","    print('Epoch: %d, Precision: %.3f' % (epoch, precision))\n","\n","    # Calculate recall\n","    recall = recall_score(ground_truths, predictions, average='weighted')\n","    print('Epoch: %d, Recall: %.3f' % (epoch, recall))\n","\n","    print(\"Epoch: %d\"%epoch)\n","    print(classification_report(ground_truths, predictions, target_names=['0', '1', '2', '3', '4', '5']))\n","\n","    if prev_accuracy < accuracy:\n","      prev_accuracy = accuracy\n","      torch.save(model.state_dict(), os.path.join(output_dir, f'model_epoch_latest.pth'))\n","      print(\"Stored:\", epoch)\n","print('Finished Training')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wNNMjq3oUFFD","outputId":"732c7176-d265-44b5-e97b-85767507e4de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[2,  1803] loss: 1.787 loss count: 28\n","Epoch: 1, Accuracy: 0.200\n","Epoch: 1, Precision: 0.229\n","Epoch: 1, Recall: 0.200\n","Epoch: 1\n","              precision    recall  f1-score   support\n","\n","           0       0.16      0.07      0.10       288\n","           1       0.26      0.08      0.12       287\n","           2       0.19      0.68      0.30       309\n","           3       0.21      0.06      0.09       283\n","           4       0.22      0.23      0.22       299\n","           5       0.33      0.05      0.09       298\n","\n","    accuracy                           0.20      1764\n","   macro avg       0.23      0.19      0.15      1764\n","weighted avg       0.23      0.20      0.16      1764\n","\n","Stored: 1\n","[3,  1803] loss: 1.786 loss count: 28\n","Epoch: 2, Accuracy: 0.189\n","Epoch: 2, Precision: 0.186\n","Epoch: 2, Recall: 0.189\n","Epoch: 2\n","              precision    recall  f1-score   support\n","\n","           0       0.19      0.12      0.15       288\n","           1       0.18      0.09      0.12       287\n","           2       0.19      0.46      0.27       309\n","           3       0.20      0.05      0.08       283\n","           4       0.19      0.30      0.24       299\n","           5       0.15      0.08      0.11       298\n","\n","    accuracy                           0.19      1764\n","   macro avg       0.19      0.18      0.16      1764\n","weighted avg       0.19      0.19      0.16      1764\n","\n","[4,  1803] loss: 1.786 loss count: 28\n","Epoch: 3, Accuracy: 0.190\n","Epoch: 3, Precision: 0.195\n","Epoch: 3, Recall: 0.190\n","Epoch: 3\n","              precision    recall  f1-score   support\n","\n","           0       0.20      0.12      0.15       288\n","           1       0.26      0.15      0.19       287\n","           2       0.19      0.41      0.26       309\n","           3       0.20      0.07      0.11       283\n","           4       0.18      0.27      0.22       299\n","           5       0.14      0.09      0.11       298\n","\n","    accuracy                           0.19      1764\n","   macro avg       0.20      0.19      0.17      1764\n","weighted avg       0.20      0.19      0.17      1764\n","\n","[5,  1803] loss: 1.785 loss count: 28\n"]}]},{"cell_type":"code","source":["# for epoch in range(1, 10):  # loop over the dataset multiple times\n","#     running_loss = 0.0\n","#     running_count = 0\n","#     xl = []\n","#     # for i, x in enumerate(train_dataset, 0):\n","#     for i, ind in enumerate(train_inds, 0):\n","#       x = train_dataset[ind]\n","#       try:\n","#         # get the inputs; data is a list of [inputs, labels]\n","#         if i%batch_size != batch_size - 1:\n","#           xx = {k: x[k] for k in x if k in req_keys}\n","#           xl.append(xx)\n","#           continue\n","\n","#         px = data_collator(xl)\n","#         px = {a: b.to(device) for a,b in px.items()}\n","#         # zero the parameter gradients\n","#         optimizer.zero_grad()\n","\n","#         # forward + backward + optimize\n","#         py = model(labels = px['labels'], protocol = px['protocol'], flow_duration = px['flow_duration'], bytes = px['bytes'], iats = px['iats'],\n","#                    input_ids = px['input_ids'], attention_mask = px['attention_mask'], direction = px['direction'], pkt_count = px['pkt_count'])\n","#         loss = criterion(py.logits, px['labels'])\n","#         loss.backward()\n","#         optimizer.step()\n","\n","#         # print statistics\n","#         running_loss += loss.item()\n","#         running_count += 1\n","#         xl = []\n","#         # if i % (batch_size - 1)*10 == 9:\n","#       except Exception as e:\n","#         print(i, e)\n","#         break\n","#     print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / running_count:.3f} loss count: {running_count}')\n","\n","#     ground_truths = []\n","#     predictions = []\n","#     # since we're not training, we don't need to calculate the gradients for our outputs\n","#     xl = []\n","#     with torch.no_grad():\n","#         for i, x in enumerate(test_dataset, 0):\n","#           try:\n","#             # get the inputs; data is a list of [inputs, labels]\n","#             if i%batch_size != batch_size - 1:\n","#               xx = {k: x[k] for k in x if k in req_keys}\n","#               xl.append(xx)\n","#               continue\n","\n","#             px = data_collator(xl)\n","#             px = {a: b.to(device) for a,b in px.items()}\n","\n","#             # forward + backward + optimize\n","#             py = model(labels = px['labels'], protocol = px['protocol'], flow_duration = px['flow_duration'], bytes = px['bytes'], iats = px['iats'],\n","#                       input_ids = px['input_ids'], attention_mask = px['attention_mask'], direction = px['direction'], pkt_count = px['pkt_count'])\n","#             # the class with the highest energy is what we choose as prediction\n","#             labels = px['labels']\n","#             outputs = py.logits\n","#             _, predicted = torch.max(outputs, 1)\n","#             ground_truths += labels.cpu().numpy().tolist()\n","#             predictions += predicted.cpu().numpy().tolist()\n","#             xl = []\n","#           except Exception as e:\n","#             print(i, e)\n","#             pass\n","\n","#     # Calculate accuracy\n","#     accuracy = accuracy_score(ground_truths, predictions)\n","#     print('Epoch: %d, Accuracy: %.3f' % (epoch, accuracy))\n","\n","#     # Calculate precision\n","#     precision = precision_score(ground_truths, predictions, average='weighted')\n","#     print('Epoch: %d, Precision: %.3f' % (epoch, precision))\n","\n","#     # Calculate recall\n","#     recall = recall_score(ground_truths, predictions, average='weighted')\n","#     print('Epoch: %d, Recall: %.3f' % (epoch, recall))\n","\n","#     print(\"Epoch: %d\"%epoch)\n","#     print(classification_report(ground_truths, predictions, target_names=['0', '1', '2', '3', '4', '5']))\n","\n","#     if prev_accuracy < accuracy:\n","#       prev_accuracy = accuracy\n","#       torch.save(model.state_dict(), os.path.join(output_dir, f'model_epoch_latest.pth'))\n","#       print(\"Stored:\", epoch)\n","# print('Finished Training')"],"metadata":{"id":"jpEKTvc4I1Do","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746655651629,"user_tz":-330,"elapsed":3817383,"user":{"displayName":"Shiva","userId":"03583737290382297870"}},"outputId":"45680f9d-53f4-48f3-afe3-3657a76334c5","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[2,  1803] loss: 1.795 loss count: 112\n","Epoch: 1, Accuracy: 0.184\n","Epoch: 1, Precision: 0.230\n","Epoch: 1, Recall: 0.184\n","Epoch: 1\n","              precision    recall  f1-score   support\n","\n","           0       0.24      0.05      0.08       274\n","           1       0.33      0.01      0.03       274\n","           2       0.18      0.96      0.30       294\n","           3       0.17      0.01      0.01       269\n","           4       0.00      0.00      0.00       285\n","           5       0.47      0.02      0.05       284\n","\n","    accuracy                           0.18      1680\n","   macro avg       0.23      0.18      0.08      1680\n","weighted avg       0.23      0.18      0.08      1680\n","\n","Stored: 1\n","[3,  1803] loss: 1.793 loss count: 112\n","Epoch: 2, Accuracy: 0.177\n","Epoch: 2, Precision: 0.132\n","Epoch: 2, Recall: 0.177\n","Epoch: 2\n","              precision    recall  f1-score   support\n","\n","           0       0.18      0.05      0.07       274\n","           1       0.09      0.00      0.01       274\n","           2       0.18      0.92      0.30       294\n","           3       0.05      0.00      0.01       269\n","           4       0.00      0.00      0.00       285\n","           5       0.30      0.04      0.07       284\n","\n","    accuracy                           0.18      1680\n","   macro avg       0.13      0.17      0.08      1680\n","weighted avg       0.13      0.18      0.08      1680\n","\n","[4,  1803] loss: 1.793 loss count: 112\n","Epoch: 3, Accuracy: 0.176\n","Epoch: 3, Precision: 0.222\n","Epoch: 3, Recall: 0.176\n","Epoch: 3\n","              precision    recall  f1-score   support\n","\n","           0       0.17      0.03      0.06       274\n","           1       0.25      0.01      0.01       274\n","           2       0.17      0.92      0.29       294\n","           3       0.11      0.01      0.02       269\n","           4       0.40      0.01      0.01       285\n","           5       0.22      0.03      0.05       284\n","\n","    accuracy                           0.18      1680\n","   macro avg       0.22      0.17      0.07      1680\n","weighted avg       0.22      0.18      0.08      1680\n","\n","[5,  1803] loss: 1.792 loss count: 112\n","Epoch: 4, Accuracy: 0.180\n","Epoch: 4, Precision: 0.269\n","Epoch: 4, Recall: 0.180\n","Epoch: 4\n","              precision    recall  f1-score   support\n","\n","           0       0.22      0.06      0.09       274\n","           1       0.09      0.01      0.01       274\n","           2       0.18      0.89      0.29       294\n","           3       0.18      0.05      0.08       269\n","           4       0.40      0.01      0.01       285\n","           5       0.54      0.02      0.05       284\n","\n","    accuracy                           0.18      1680\n","   macro avg       0.27      0.17      0.09      1680\n","weighted avg       0.27      0.18      0.09      1680\n","\n","[6,  1803] loss: 1.791 loss count: 112\n","Epoch: 5, Accuracy: 0.179\n","Epoch: 5, Precision: 0.153\n","Epoch: 5, Recall: 0.179\n","Epoch: 5\n","              precision    recall  f1-score   support\n","\n","           0       0.19      0.05      0.09       274\n","           1       0.18      0.01      0.02       274\n","           2       0.18      0.93      0.30       294\n","           3       0.06      0.00      0.01       269\n","           4       0.00      0.00      0.00       285\n","           5       0.31      0.04      0.06       284\n","\n","    accuracy                           0.18      1680\n","   macro avg       0.15      0.17      0.08      1680\n","weighted avg       0.15      0.18      0.08      1680\n","\n","[7,  1803] loss: 1.790 loss count: 112\n","Epoch: 6, Accuracy: 0.182\n","Epoch: 6, Precision: 0.288\n","Epoch: 6, Recall: 0.182\n","Epoch: 6\n","              precision    recall  f1-score   support\n","\n","           0       0.14      0.04      0.07       274\n","           1       0.18      0.01      0.01       274\n","           2       0.18      0.87      0.29       294\n","           3       0.23      0.08      0.12       269\n","           4       0.60      0.01      0.02       285\n","           5       0.39      0.03      0.06       284\n","\n","    accuracy                           0.18      1680\n","   macro avg       0.29      0.17      0.10      1680\n","weighted avg       0.29      0.18      0.10      1680\n","\n","[8,  1803] loss: 1.789 loss count: 112\n","Epoch: 7, Accuracy: 0.182\n","Epoch: 7, Precision: 0.223\n","Epoch: 7, Recall: 0.182\n","Epoch: 7\n","              precision    recall  f1-score   support\n","\n","           0       0.23      0.07      0.11       274\n","           1       0.10      0.01      0.01       274\n","           2       0.18      0.89      0.30       294\n","           3       0.19      0.05      0.08       269\n","           4       0.40      0.01      0.01       285\n","           5       0.24      0.03      0.05       284\n","\n","    accuracy                           0.18      1680\n","   macro avg       0.22      0.18      0.09      1680\n","weighted avg       0.22      0.18      0.10      1680\n","\n","[9,  1803] loss: 1.791 loss count: 112\n","Epoch: 8, Accuracy: 0.180\n","Epoch: 8, Precision: 0.191\n","Epoch: 8, Recall: 0.180\n","Epoch: 8\n","              precision    recall  f1-score   support\n","\n","           0       0.21      0.05      0.08       274\n","           1       0.08      0.01      0.01       274\n","           2       0.18      0.94      0.30       294\n","           3       0.06      0.00      0.01       269\n","           4       0.33      0.00      0.01       285\n","           5       0.28      0.03      0.05       284\n","\n","    accuracy                           0.18      1680\n","   macro avg       0.19      0.17      0.08      1680\n","weighted avg       0.19      0.18      0.08      1680\n","\n","[10,  1803] loss: 1.788 loss count: 112\n","Epoch: 9, Accuracy: 0.186\n","Epoch: 9, Precision: 0.323\n","Epoch: 9, Recall: 0.186\n","Epoch: 9\n","              precision    recall  f1-score   support\n","\n","           0       0.25      0.07      0.11       274\n","           1       0.14      0.01      0.02       274\n","           2       0.18      0.92      0.30       294\n","           3       0.21      0.06      0.09       269\n","           4       1.00      0.01      0.02       285\n","           5       0.14      0.00      0.01       284\n","\n","    accuracy                           0.19      1680\n","   macro avg       0.32      0.18      0.09      1680\n","weighted avg       0.32      0.19      0.09      1680\n","\n","Stored: 9\n","Finished Training\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"xAvmtCspdl8U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import runtime\n","runtime.unassign()"],"metadata":{"id":"BfDl0YUniLGR"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[],"collapsed_sections":["TOhMIvYr10Ej","CfMFQwqL10Em","J6lpW2rr10Eo"],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"b97e3290eb3c425fa1cfe3c1d73a8509":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a89c73c2cce44f63a3f568dee6362dab","IPY_MODEL_e9f190d768df42cab5c0c118e40d97c2","IPY_MODEL_830127a3cee647eca484f3337d6c0ba0"],"layout":"IPY_MODEL_7c69438a020344bf9b3fb21741186277"}},"a89c73c2cce44f63a3f568dee6362dab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f80fd54af384875979a6beec1923ad6","placeholder":"​","style":"IPY_MODEL_3f241c28568f4ad2911e993cb9f9ca5b","value":"Generating train split: "}},"e9f190d768df42cab5c0c118e40d97c2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b631f1c39a6415d87eb80db8bdccc4c","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ac144506684f45cb8e7e21e5f6940d06","value":1}},"830127a3cee647eca484f3337d6c0ba0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_423743d0922d48fbb65095b4beb271eb","placeholder":"​","style":"IPY_MODEL_73f3610e994a4afcb4396a54ec2d5ebb","value":" 1803/0 [00:00&lt;00:00, 6041.91 examples/s]"}},"7c69438a020344bf9b3fb21741186277":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f80fd54af384875979a6beec1923ad6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f241c28568f4ad2911e993cb9f9ca5b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6b631f1c39a6415d87eb80db8bdccc4c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"ac144506684f45cb8e7e21e5f6940d06":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"423743d0922d48fbb65095b4beb271eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73f3610e994a4afcb4396a54ec2d5ebb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c8be958ba605448b8fa4d4dc0c01e30d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4d04e8fb12c14a8c9b4461b86a29aa35","IPY_MODEL_ef1d64c996904e17b7d647daa01b6e24","IPY_MODEL_e85761de758b415997db2ae63e81fe6a"],"layout":"IPY_MODEL_d79a70eec91f408ab208fd9f847e8134"}},"4d04e8fb12c14a8c9b4461b86a29aa35":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d90e8fb52ac4405f89baed05bd6d204e","placeholder":"​","style":"IPY_MODEL_a3ab5de959364ce8bb3148222017cc26","value":"Map: 100%"}},"ef1d64c996904e17b7d647daa01b6e24":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed8b5bbbddab4d9486c2d5ca4c7b88f5","max":1803,"min":0,"orientation":"horizontal","style":"IPY_MODEL_432850d9a68b49beae7101109ecd044f","value":1803}},"e85761de758b415997db2ae63e81fe6a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45d4703696784361900428f548f37ecc","placeholder":"​","style":"IPY_MODEL_d15c1e1633a44e8485e318f3ab66dd70","value":" 1803/1803 [00:07&lt;00:00, 233.42 examples/s]"}},"d79a70eec91f408ab208fd9f847e8134":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d90e8fb52ac4405f89baed05bd6d204e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3ab5de959364ce8bb3148222017cc26":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed8b5bbbddab4d9486c2d5ca4c7b88f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"432850d9a68b49beae7101109ecd044f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"45d4703696784361900428f548f37ecc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d15c1e1633a44e8485e318f3ab66dd70":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}